
现在我们需要学习工作队列的高级用法：**如何创建和使用自定义工作队列？**

简单来说，**自定义工作队列**就像企业的"专项工作组"。如果说共享工作队列是公司的"公共会议室"（大家都可以用，但可能要排队），那么自定义工作队列就是"专属办公室"（只为特定项目服务，响应更快，控制更精确）。当你的驱动有特殊性能要求或需要独立控制时，就需要建立自己的专属工作队列。

> [!note]+ 重要笔记
> 
> 自定义工作队列由内核或驱动程序创建，用于处理特定任务。与共享工作队列相比，它提供了更好的隔离性、可控性和性能保证。

## 1 自定义工作队列基础

### 1.1 自定义和共享工作队列的区别

**共享工作队列**：
- 由`内核管理的全局工作队列`
- 多个驱动程序共享使用，可能存在竞争
- 适用于对性能要求不高的简单场景
- 使用简单，但控制能力有限

**自定义工作队列**：
- 由`驱动程序创建的专用工作队列`
- 独立的工作线程，不与其他驱动竞争资源
- 可以设置特定的优先级和CPU亲和性
- 适用于对性能和响应时间有严格要求的场景

> [!example]+ 示例
> 
> 这就像餐厅的两种服务模式：
> 
> - **共享工作队列**：大厅的公共服务员，为所有客人服务，可能需要等待
> - **自定义工作队列**：VIP包间的专属服务员，只为VIP客人服务，响应更快

换句话说，当你的驱动处理的任务非常重要或者对时间要求很严格时，就应该考虑使用自定义工作队列。

### 1.2 核心数据结构

**工作项结构体（work_struct）**
```c
struct work_struct{
	atomic_long_t data;             //工作项的数据字段
	struct list_head_entry;         //工作项在工作队列中的链表节点
	work_func_t func;               //工作项的处理函数
#ifdef CONFIG_LOCKDEP
	struct lockdep_map lockdep_map; //锁依赖性映射
#endif
}
```

**工作队列结构体（workqueue_struct）**
```c
struct workqueue_struct{
	struct list_head          pwqs;                 // 工作队列上的挂起工作项列表
	struct list_head          delayed_works;        // 延迟执行的工作项列表
	struct delayed_work_timer dwork_timer;          // 延迟工作项的定时器
	struct workqueue_attrs    *unbound_attrs;       // 无绑定工作队列的属性
	struct pool_workqueue     *dfl_pwq;             // 默认的池化工作队列
}
```

> [!tip]+ 重要提示
> 
> 这两个结构体的关系就像"任务单"和"任务管理系统"：
> 
> - **work_struct**：具体的任务单，记录要做什么工作
> - **workqueue_struct**：任务管理系统，负责组织和调度这些任务

## 2 自定义工作队列API

### 2.1 工作队列创建和销毁

**创建工作队列**：为每个CPU都创建一个CPU相关的工作队列，适用于需要充分利用多核性能的场景
```c
struct workqueue_struct *create_workqueue(const char *name);
```
- **name**：创建的工作队列名字
- **返回值**：成功返回workqueue_struct指针，失败返回NULL


**创建单线程工作队列**：只为一个CPU创建工作队列，适用于不需要多核并行处理的场景。
```c
#define create_singlethread_workqueue(name) \
    alloc_workqueue("%s", WQ_SINGLE_THREAD, 1, name)
```

> [!warning]+ 警告或注意
> 
> 选择创建多线程还是单线程工作队列要根据实际需求：
> 
> - 如果任务可以并行处理且对性能要求高，选择create_workqueue
> - 如果任务需要顺序执行或者系统资源有限，选择create_singlethread_workqueue

**销毁工作队列**：删除自定义的工作队列，释放相关资源。
```c
void destroy_workqueue(struct workqueue_struct *wq);
```

### 2.2 工作调度和控制

**提交工作到指定CPU**：
```c
bool queue_work_on(int cpu, struct workqueue_struct *wq, struct work_struct *work);
```
- **cpu**：指定执行工作的CPU编号
- **wq**：目标工作队列
- **work**：要执行的工作项
- **返回值**：成功调度返回true，失败返回false

**通用工作提交函数**：将工作项添加到工作队列中，由系统自动选择合适的CPU执行
```c
static inline bool queue_work(struct workqueue_struct *wq, struct work_struct *work)
{
    return queue_work_on(WORK_CPU_UNBOUND, wq, work);
}
```


**取消工作执行**：取消已经调度的工作，如果工作正在执行则等待其完成
```c
bool cancel_work_sync(struct work_struct *work);
```


**刷新工作队列**：刷新工作队列，告诉内核尽快处理队列上的所有工作
```c
void flush_workqueue(struct workqueue_struct *wq);
```

> [!example]+ 示例
> 
> 这些函数就像管理"专属团队"的工具：
> 
> - **queue_work**：给团队分配新任务
> - **cancel_work_sync**：取消某个任务（等当前工作完成）
> - **flush_workqueue**：催促团队加快处理所有任务
> - **destroy_workqueue**：解散整个团队

## 3 实践应用案例

### 3.1 完整驱动实现

让我们通过一个完整的例子来理解自定义工作队列的使用：

**Makefile配置**：
```makefile
export ARCH=arm64                      # 设置平台架构
export CROSS_COMPILE=aarch64-linux-gnu-# 交叉编译器前缀
obj-m := interrupt.o
KDIR :=/home/Linux/linux_sdk/kernel    # 内核目录路径

PWD ?= $(shell pwd)
all:
    make -C $(KDIR) M=$(PWD) modules    # 编译操作
clean:
    make -C $(KDIR) M=$(PWD) clean      # 清理操作
```

**完整驱动代码**：
```c
#include <linux/module.h>
#include <linux/init.h>
#include <linux/interrupt.h>
#include <linux/gpio.h>
#include <linux/delay.h>
#include <linux/workqueue.h>

int irq;
struct workqueue_struct *test_workqueue;    // 自定义工作队列
struct work_struct test_workqueue_work;     // 工作项

// 工作项处理函数
void test_work(struct work_struct *work)
{
    // 可以执行耗时操作，因为运行在进程上下文中
    msleep(1000);
    printk("This is test_work in custom workqueue\n");
}

// 中断处理函数
irqreturn_t test_interrupt(int irq, void *args)
{
    printk("This is test_interrupt\n");
    
    // 提交工作项到自定义工作队列
    queue_work(test_workqueue, &test_workqueue_work);
    
    return IRQ_RETVAL(IRQ_HANDLED);
}

static int interrupt_irq_init(void)
{
    int ret;
    
    // 将GPIO映射为中断号
    irq = gpio_to_irq(42);
    printk("irq is %d\n", irq);

    // 请求中断
    ret = request_irq(irq, test_interrupt, IRQF_TRIGGER_RISING, "test", NULL);
    if (ret < 0) {
        printk("request_irq is error\n");
        return -1;
    }

    // 创建自定义工作队列
    test_workqueue = create_workqueue("test_workqueue");
    if (!test_workqueue) {
        printk("create_workqueue failed\n");
        free_irq(irq, NULL);
        return -1;
    }
    
    // 初始化工作项
    INIT_WORK(&test_workqueue_work, test_work);

    return 0;
}

static void interrupt_irq_exit(void)
{
    // 释放中断
    free_irq(irq, NULL);
    
    // 取消工作项（等待当前工作完成）
    cancel_work_sync(&test_workqueue_work);
    
    // 刷新工作队列（处理所有挂起的工作）
    flush_workqueue(test_workqueue);
    
    // 销毁工作队列
    destroy_workqueue(test_workqueue);
    
    printk("bye bye\n");
}

module_init(interrupt_irq_init);
module_exit(interrupt_irq_exit);

MODULE_LICENSE("GPL");
```

**---------------代码流程分析---------------**
**初始化阶段**：
1. **GPIO中断配置**：将GPIO 42映射为中断号并注册中断处理函数
2. **创建自定义工作队列**：建立专属的工作处理线程
3. **初始化工作项**：绑定具体的处理函数
**运行阶段**：
4. **中断触发**：GPIO中断发生，调用test_interrupt函数
5. **快速响应**：在中断上下文中快速处理并提交工作项
6. **后台处理**：自定义工作队列的线程执行耗时的test_work函数
**清理阶段**：
7. **等待完成**：取消工作项并等待当前工作完成
8. **刷新队列**：处理所有挂起的工作
9. **资源释放**：销毁工作队列和释放中断

> [!tip]+ 重要提示
> 
> 注意清理顺序的重要性：
> 
> 1. 先停止新工作的产生（释放中断）
> 2. 等待当前工作完成（cancel_work_sync）
> 3. 处理遗留工作（flush_workqueue）
> 4. 最后销毁工作队列（destroy_workqueue）

### 3.2 与共享工作队列的对比

**如果使用共享工作队列的写法**：
```c
// 共享工作队列版本
static int interrupt_irq_init(void)
{
    // ... 中断配置代码相同 ...
    
    // 只需要初始化工作项，不需要创建工作队列
    INIT_WORK(&test_workqueue_work, test_work);
    
    return 0;
}

// 中断处理函数
irqreturn_t test_interrupt(int irq, void *args)
{
    printk("This is test_interrupt\n");
    
    // 使用共享工作队列
    schedule_work(&test_workqueue_work);
    
    return IRQ_RETVAL(IRQ_HANDLED);
}
```

**对比总结**：

|特性|共享工作队列|自定义工作队列|
|---|---|---|
|**代码复杂度**|简单|相对复杂|
|**资源占用**|低|高（独立线程）|
|**性能隔离**|无|完全隔离|
|**可控性**|有限|完全可控|
|**适用场景**|一般应用|高性能要求|

## 4 内部实现机制

### 4.1 queue_work内部实现

让我们深入了解queue_work函数的内部实现：
```c
/**
 * queue_work - queue work on a workqueue
 * @wq: workqueue to use
 * @work: work to queue
 *
 * Returns %false if @work was already on a queue, %true otherwise.
 */
static inline bool queue_work(struct workqueue_struct *wq,
                             struct work_struct *work)
{
    return queue_work_on(WORK_CPU_UNBOUND, wq, work);
}
```

**queue_work_on核心实现**：
```c
bool queue_work_on(int cpu, struct workqueue_struct *wq,
                   struct work_struct *work)
{
    bool ret = false;
    unsigned long flags;

    // 关闭本地中断，保证原子性
    local_irq_save(flags);

    // 检查工作是否已经在队列中，避免重复添加
    if (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {
        __queue_work(cpu, wq, work);
        ret = true;
    }

    // 恢复中断状态
    local_irq_restore(flags);
    return ret;
}
EXPORT_SYMBOL(queue_work_on);
```

**实现原理解析**：
1. **原子性保证**：通过关闭中断确保操作的原子性
2. **重复检查**：使用位操作检查工作是否已在队列中
3. **实际入队**：调用__queue_work执行具体的入队操作
4. **状态返回**：返回操作结果

> [!note]+ 重要笔记
> 
> 这种设计确保了：
> 
> - 同一个工作项不会被重复添加到队列
> - 操作过程是原子的，不会被中断打断
> - 提供明确的操作结果反馈

换句话说，内核在工作队列的实现上采用了非常严谨的设计，确保了系统的稳定性和可靠性。

## 5 总结

通过这个章节的学习，我们全面掌握了自定义工作队列的使用方法：

> [!abstract]+ 摘要或总结
> 
> **核心技能掌握**：
> 
> - 理解了自定义工作队列与共享工作队列的区别和适用场景
> - 掌握了工作队列和工作项的核心数据结构设计
> - 学会了创建、使用和销毁自定义工作队列的完整流程
> - 通过实际代码案例体验了自定义工作队列的应用方法
> - 了解了内核工作队列机制的内部实现原理

自定义工作队列为需要高性能和精确控制的驱动程序提供了强大的工具。虽然它比共享工作队列更复杂，但在对响应时间、性能隔离有严格要求的场景下，它是不可替代的选择。正确使用自定义工作队列可以显著提升驱动程序的性能和可靠性。

> [!question]+ 常见问题
> 
> **Q**: 什么时候应该使用自定义工作队列而不是共享工作队列？ 
> **A**: 当你的驱动有以下需求时应该考虑自定义工作队列：
> 1. 对响应时间有严格要求；
> 2. 工作负载较重，担心影响其他驱动；
> 3. 需要特定的CPU亲和性或优先级设置；
> 4. 需要独立的错误处理和监控
> 
> 一般原则是：简单应用用共享队列，高性能应用用自定义队列。
