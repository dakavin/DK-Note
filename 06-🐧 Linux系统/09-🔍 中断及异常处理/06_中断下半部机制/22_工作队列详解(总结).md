现在我们需要从整体架构的角度来理解：**Linux工作队列机制是如何设计和演进的？**

简单来说，**工作队列**就像深入了解一个"现代化工厂的管理体系"。如果说之前我们学习的是如何使用工厂的生产线（基本API），那么现在我们要学习整个工厂是如何组织的：有多少车间（工作线程池）、每个车间有多少工人（工作线程）、任务是如何分配和调度的（CMWQ机制），以及这套体系是如何从简单的作坊发展成现代化工厂的。

> [!note]+ 重要笔记
> 
> 工作队列机制是Linux内核中最重要的下半部处理机制之一，经历了从简单到复杂、从低效到高效的重要演进过程。理解其设计思想和架构对于深入掌握Linux内核调度机制具有重要意义。

## 1 工作队列机制概述

### 1.1 工作队列的基本原理

**工作队列（workqueue）机制**是除了软中断和tasklet以外最常用的一种下半部机制。工作队列的基本原理是把**work（需要推迟执行的函数）** 交由内核线程来执行，它总是在进程上下文中执行。

**工作队列的核心优势**：
- 利用进程上下文来执行中断下半部操作
- 允许重新调度和睡眠，是异步执行的进程上下文
- 能解决软中断和tasklet执行时间过长导致的系统实时性下降问题

换句话说，工作队列就像企业的"项目管理部门"，它不会让重要人员（中断处理）去做耗时的杂活，而是把这些工作交给专门的团队（内核线程）去处理。

### 1.2 工作队列的基本组成

当驱动或者内核子系统在进程上下文中有异步执行的工作任务时，可以使用以下组件：

**核心组件说明**：
- **工作项（work item）**：描述工作任务，包括该工作任务执行的回调函数
- **工作队列（workqueue）**：存放工作项的队列
- **工作线程（worker）**：执行工作任务回调函数的内核线程

> [!example]+ 示例
> 
> 这个组合就像快递系统：
> 
> - **工作项**：每个快递包裹（包含收件信息和处理要求）
> - **工作队列**：快递分拣中心的传送带
> - **工作线程**：负责配送的快递员

把工作项添加到队列中，然后内核线程会执行这个工作任务的回调函数，整个过程异步进行，不会阻塞系统的正常运行。

## 2 早期工作队列的问题

### 2.1 历史发展背景

工作队列最早是在**Linux 2.5.x内核开发期间**被引入的机制，早期的工作队列设计比较简单，由多线程（每个CPU默认有一个工作线程）和单线程（用户可以自行创建工作线程）组成。

![image.png|500](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2025/06/ddbe2946205127aa7e68f77f07ff38c6.png)

在长期测试中发现了几个严重问题，这些问题限制了工作队列的性能和可扩展性。

### 2.2 三大核心问题

**问题一：内核线程数量过多**
虽然系统中有默认的一套工作线程（Kevents），但是很多驱动和子系统喜欢自行创建工作线程，如调用`create_workqueue()`函数。这样在大型系统（CPU数量比较多的服务器）中可能内核启动结束之后就耗尽了系统PID资源。

> [!warning]+ 警告或注意
> 
> 在早期设计中，每个CPU、每个工作队列都会创建独立的工作线程。假设系统有32个CPU，创建了10个工作队列，就需要320个内核线程，这会严重消耗系统资源。

**问题二：并发性比较差**
多线程的工作线程和CPU是绑定的，如CPU0上的某个工作线程有A、B和C三个工作。假设执行工作A的回调函数时发生了睡眠和调度，CPU0就会被调度出以执行其他的进程。对于B和C来说，它们只能等待CPU0重新调度、执行该工作线程，尽管其他CPU比较空闲，也没有办法迁移到其他CPU上。

**问题三：死锁问题**
系统有一个默认的工作队列，如果有很多工作运行在默认的工作队列上，并且它们有一些数据的依赖关系，那么很有可能会产生死锁。解决办法是为每一个可能产生死锁的工作创建一个专职的工作线程，这样又回到问题1了。

> [!example]+ 示例
> 
> 这些问题就像早期工厂的管理缺陷：
> 
> - **线程过多**：每个产品线都有专门的工人，造成人力浪费
> - **并发性差**：工人只能在固定车间工作，不能灵活调配
> - **死锁问题**：不同产品线的工人互相等待资源，形成僵局

换句话说，早期的工作队列设计简单粗暴，缺乏统一管理和资源优化，在大规模系统中暴露出严重的可扩展性问题

## 3 CMWQ架构的引入

### 3.1 CMWQ解决方案

为了解决早期工作队列的问题，社区专家Tejun Heo在**Linux 2.6.36**中提出了一套解决方案——**并发托管工作队列（Concurrency-Managed Workqueue，CMWQ）**。

![image.png|500](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2025/06/e3dfb2bb15699c1e0ef288922828b7e3.png)

> [!tip]+ 重要提示
> 
> CMWQ的核心思想是"资源共享和动态管理"，就像现代工厂采用"共享车间+柔性生产线"的模式，大大提高了资源利用效率。

### 3.2 CMWQ核心设计思想

**基本工作机制**：
- **执行工作任务的线程**称为工作线程
- **工作线程会串行化地执行**挂载到队列中所有的工作
- **如果队列中没有工作**，那么该工作线程就会变成空闲状态

**工作线程池（worker-pool）概念**：

为了管理众多工作线程，CMWQ提出了工作线程池的概念，工作线程池有两种类型：

**BOUND类型**：
- 可以理解为Per-CPU类型，每个CPU都有工作线程池
- 工作线程绑定到特定CPU上执行
- 适用于对CPU亲和性有要求的工作

**UNBOUND类型**：
- 不和具体CPU绑定的工作线程池
- 工作线程可以在任意CPU上执行
- 适用于对CPU亲和性没有特殊要求的工作

> [!note]+ 重要笔记
> 
> 这两种工作线程池都会定义两个线程池：
> 
> - 一个给**普通优先级**的工作使用
> - 另一个给**高优先级**的工作使用
> 
> 这些工作线程池中的线程数量是**动态分配和管理**的，而不是固定的。

**动态线程管理机制**：

当工作线程睡眠时，会检查是否需要唤醒更多的工作线程，如有需要，会唤醒同一个工作线程池中处于空闲状态的工作线程。

换句话说，CMWQ实现了"按需分配、动态调整"的资源管理模式，既避免了资源浪费，又确保了工作的及时处理。

## 4 工作队列数据结构架构

### 4.1 整体架构关系

根据工作队列机制，最小的调度单元是**工作项**，有的书中称为工作任务，由`work_struct`数据结构来抽象和描述。

```c
workqueue_struct
  |
  +--> pool_workqueue
         |
         +--> worker_pool
                |
                +--> worker
                        |
                        +--> work_struct
```

![image.png|500](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2025/06/ae131fe433bcd364a8f6ea3d854b3b4d.png)

**各组件功能说明**：
- **work_struct**：工作队列的核心结构，表示一个需要执行的工作任务。每一个工作任务都由`work_struct`表示，并被调度到`worker`中运行
- **workqueue_struct**：工作队列的核心管理结构，表示一个工作队列。工作队列可以是共享队列，也可以是用户自定义队列
- **worker**：工作队列中实际执行任务的线程，每个`worker`对应一个内核线程，用来处理队列中的工作任务
- **worker_pool**：一个内核线程池，管理多个`worker`，为`workqueue_struct`提供资源。它的引入是为了更高效地调度线程，并支持多队列共享资源
- **pool_workqueue**：连接`workqueue_struct`和`worker_pool`的桥梁，负责在两者之间建立联系，并分发任务到线程池中

> [!example]+ 示例
> 
> 这个架构就像现代企业的组织结构：
> 
> - **work_struct**：具体的工作任务（项目需求）
> - **worker**：实际执行工作的员工
> - **worker_pool**：部门或团队（员工集合）
> - **pool_workqueue**：项目经理（连接需求和团队）
> - **workqueue_struct**：业务部门（管理多个项目）

### 4.2 work_struct结构详解

```c
// include/linux/workqueue.h
struct work_struct {
     atomic_long_t data;
     struct list_head entry;
     work_func_t func;
};
```

![image.png|500](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2025/06/b12358f715b40d16b58fd2db9bfcc350.png)

**成员详细说明**：
- **data成员**：包括两部分内容
    - 低位部分是work的标志位
    - 剩余的位通常用于存放上一次运行的worker_pool的ID或pool_workqueue的指针
    - 存放的内容由WORK_STRUCT_PWQ标志位来决定
- **func成员**：work的处理函数，即具体要执行的工作内容
- **entry成员**：用于把work挂到其他队列上的链表节点


> [!tip]+ 重要提示
> 
> work_struct数据结构的定义比较简单，但设计巧妙。data字段的复用设计体现了内核开发者对内存使用的精细优化。

### 4.3 worker结构详解

work运行在内核线程中，这个内核线程在代码中称为**worker**，worker类似于流水线中的工人，work类似于工人的工作。

```c
// kernel/workqueue_internal.h
struct worker {
     struct work_struct *current_work;
     work_func_t   current_func;
     struct pool_workqueue *current_pwq;
     struct list_head  scheduled;
     struct task_struct *task;
     struct worker_pool   *pool;
     int          id;
     struct list_head      node;
     ...
};
```
- **current_work**：当前正在处理的work，表示工人手头的任务
- **current_func**：当前正在执行的work回调函数
- **current_pwq**：当前work所属的pool_workqueue
- **scheduled**：所有被调度并正准备执行的work都挂入该链表中
- **task**：该工作线程的task_struct数据结构，即对应的内核线程
- **pool**：该工作线程所属的worker_pool
- **id**：工作线程的ID，用于标识和管理

### 4.4 worker_pool结构详解

CMWQ提出了工作线程池的概念，代码中使用**worker_pool**数据结构来抽象和描述：

```c
// kernel/workqueue.c
struct worker_pool {
     spinlock_t     lock;
     int            cpu;
     int            node;
     int            id;
     unsigned int       flags;
     struct list_head   worklist;
     int            nr_workers;
     int            nr_idle;
     struct list_head   idle_list;
     struct list_head   workers;
     struct workqueue_attrs*attrs;
     atomic_t     nr_running ____cacheline_aligned_in_smp;
     struct rcu_head       rcu;
     ...
} ____cacheline_aligned_in_smp;
```
- **lock**：用于保护工作线程池的自旋锁
- **cpu**：对于BOUND类型的工作队列，cpu表示绑定的CPU ID；对于UNBOUND类型的工作线程池，该值为-1
- **node**：对于UNBOUND类型的工作队列，node表示该工作线程池所属内存节点的ID
- **worklist**：处于pending状态的work会挂入该链表中
- **nr_workers**：工作线程的数量
- **nr_idle**：处于idle状态的工作线程的数量
- **idle_list**：处于idle状态的工作线程会挂入该链表中
- **workers**：该工作线程池管理的工作线程会挂入该链表中

> [!warning]+ 警告或注意
> 
> **nr_running成员的特殊设计**：计数值，用于管理worker的创建和销毁，表示正在运行中的worker数量。该成员频繁在多核之间读写，因此让该成员独占一个缓冲行，避免多核CPU在读写时引发"缓存行伪共享"问题。

**工作线程池的CPU分布**：
```c
// kernel/workqueue.c
static DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);
```
工作线程池是Per-CPU类型的概念，每个CPU都有工作线程池。准确地说，每个CPU有**两个工作线程池**：
- 一个用于普通优先级的工作线程
- 另一个用于高优先级的工作线程

### 4.5 pool_workqueue结构详解

CMWQ还定义了一个**pool_workqueue**数据结构，它是连接工作队列和工作线程池的枢纽：
```c
// kernel/workqueue.c
struct pool_workqueue {
     struct worker_pool    *pool;
     struct workqueue_struct *wq;
     int          nr_active;
     int          max_active;
     struct list_head  delayed_works;
     struct rcu_head       rcu;
     ...
} __aligned(1 << WORK_STRUCT_FLAG_BITS);
```

**成员功能说明**：
- **pool**：指向工作线程池指针
- **wq**：指向所属的工作队列
- **nr_active**：活跃的work数量
- **max_active**：活跃的work最大数量
- **delayed_works**：链表头，延迟执行的work可以挂入该链表

> [!note]+ 重要笔记
> 
> pool_workqueue数据结构按照256字节对齐（WORK_STRUCT_FLAG_BITS为8），这样方便把该数据结构指针的Bit[8:31]位存放到work->data中，work->data字段的低8位用于存放标志位。

### 4.6 workqueue_struct结构详解

系统中所有的工作队列（包括系统默认的工作队列和驱动开发者新创建的工作队列）共享一组工作线程池：
```c
// kernel/workqueue.c
struct workqueue_struct {
     struct list_head   pwqs;
     struct list_head   list;
     struct list_head   maydays;
     struct worker      *rescuer;
     struct workqueue_attrs*unbound_attrs;
     struct pool_workqueue*dfl_pwq;
     char         name[WQ_NAME_LEN];
     unsigned int    flags ____cacheline_aligned;
     struct pool_workqueue __percpu *cpu_pwqs;
     ...
};
```
- **pwqs**：所有的pool-workqueue数据结构都挂入链表中
- **list**：链表节点。系统定义一个全局的链表工作队列，所有的工作队列挂入该链表
- **rescuer**：rescuer工作线程。内存紧张时创建新的工作线程可能会失败，如果创建工作队列时设置了WQ_MEM_RECLAIM标志位，那么rescuer工作线程会接管这种情况
- **name**：该工作队列的名字
- **flags**：标志位，包括WQ_UNBOUND、WQ_HIGHPRI、WQ_FREEZABLE等
- **cpu_pwqs**：指向Per-CPU类型的pool_workqueue

换句话说，workqueue_struct就像企业的"业务部门"，它管理多个项目（工作），协调各种资源（线程池），并提供应急预案（rescuer机制）。

## 5 工作队列的四种使用模式

### 5.1 使用模式分类

根据不同的应用需求，工作队列提供了四种主要的使用模式：

**共享工作队列模式（CPU绑定）**：
- `INIT_WORK`：初始化工作项
- `schedule_work`：把任务发给内核创建的共享队列

**自定义工作队列模式（CPU绑定）**：
- `create_workqueue`：创建一个专用队列
- `INIT_WORK`：初始化工作项
- `queue_work`：把任务发给自己创建的队列

**延迟工作模式（CPU绑定）**：
- `create_workqueue`：创建一个队列
- `INIT_DELAYED_WORK`：在INIT_WORK基础上增加延时功能
- `queue_delayed_work`：把任务发给自己创建的队列，并告知延后时间
- 或者`schedule_delayed_work`：使用共享队列的延迟工作

**并发工作队列模式（不绑定CPU）**：
- `alloc_workqueue`：创建高级工作队列
- `INIT_WORK`：初始化工作项
- `queue_work`：把任务发给自己创建的队列

> [!tip]+ 重要提示
> 
> 四种模式的选择依据：
> 
> - **共享模式**：简单任务，对性能要求不高
> - **自定义模式**：需要独立控制的任务
> - **延迟模式**：需要定时执行的任务
> - **并发模式**：高性能、跨CPU的任务

### 5.2 模式选择指南

**使用场景建议**：

|模式|适用场景|优势|劣势|
|---|---|---|---|
|**共享工作队列**|简单的异步处理|资源占用小，使用简单|可能受其他任务影响|
|**自定义工作队列**|需要独立控制的任务|性能隔离，可控性强|资源占用相对较大|
|**延迟工作**|定时任务、消抖处理|精确时间控制|相对复杂|
|**并发工作队列**|高性能、多CPU任务|最大化CPU利用率|配置复杂|

> [!example]+ 示例
> 
> 这四种模式就像不同的工作安排方式：
> 
> - **共享模式**：使用公司的公共会议室
> - **自定义模式**：申请专用办公室
> - **延迟模式**：预约未来的会议时间
> - **并发模式**：组建跨部门项目团队

## 6 总结

通过这个章节的学习，我们深入了解了Linux工作队列机制的完整架构：

> [!abstract]+ 摘要或总结
> 
> **核心知识掌握**：
> 
> - 理解了工作队列从早期简单设计到CMWQ架构的重要演进过程
> - 掌握了早期工作队列的三大问题及CMWQ的解决方案
> - 学习了工作队列五大核心数据结构的设计思想和相互关系
> - 了解了BOUND和UNBOUND两种工作线程池的区别和应用场景
> - 认识了四种工作队列使用模式的特点和选择依据

工作队列机制体现了Linux内核设计的精妙之处，通过CMWQ架构实现了资源的统一管理和动态调度，既解决了早期设计的问题，又为各种复杂应用场景提供了灵活的解决方案。深入理解这套机制有助于我们编写更高效的驱动程序，并为内核调试和性能优化奠定基础。

> [!question]+ 常见问题
> 
> **Q**: CMWQ相比早期工作队列的最大改进是什么？ 
> **A**: CMWQ的最大改进是引入了"工作线程池共享"的概念。不再是每个工作队列都有独立的工作线程，而是多个工作队列共享同一组工作线程池，并通过动态管理机制按需分配线程。这样既大大减少了内核线程数量，又提高了资源利用效率和并发性能。

