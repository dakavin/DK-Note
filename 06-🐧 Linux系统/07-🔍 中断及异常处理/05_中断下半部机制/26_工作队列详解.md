
工作队列（workqueue）机制是除了软中断和tasklet以外最常用的一种下半部机制。工作队列的基本原理是把work（需要推迟执行的函数）交由内核线程来执行，它总是在进程上下文中执行。工作队列的优点是利用进程上下文来执行中断下半部操作，因此工作队列允许重新调度和睡眠，是异步执行的进程上下文。另外，工作队列还能解决软中断和tasklet执行时间过长导致的系统实时性下降等问题。

当驱动或者内核子系统在进程上下文中有异步执行的工作任务时，可以使用工作项（work item）来描述工作任务，包括该工作任务执行的回调函数。把工作项添加到一个队列中，然后一个内核线程会执行这个工作任务的回调函数。这里工作项称为工作，队列称为工作队列（workqueue），内核线程称为工作线程（worker）。

## 1 工作队列的问题

---

工作队列最早是在Linux 2.5.x内核开发期间被引入的机制，早期的工作队列的设计比较简单，由多线程（每个CPU默认有一个工作线程）和单线程（用户可以自行创建工作线程）组成。在长期测试中发现如下问题。

![image.png|500](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2025/06/ddbe2946205127aa7e68f77f07ff38c6.png)


1. 内核线程数量太多。虽然系统中有默认的一套工作线程（Kevents），但是很多驱动和子系统喜欢自行创建工作线程，如调用create_workqueue()函数，这样在大型系统（CPU数量比较多的服务器）中可能内核启动结束之后就耗尽了系统PID资源。
    
2. 并发性比较差。多线程的工作线程和CPU是一绑定的，如CPU0上的某个工作线程有A、B和C三个工作。假设执行工作 A的回调函数时发生了睡眠和调度，CPU0就会被调度出以执行其他的进程，对于B和C来说，它们只能等待CPU0重新调度、执行该工作线程，尽管其他CPU比较空闲，也没有办法迁移到其他CPU上。
    
3. 死锁问题。系统有一个默认的工作队列，如果有很多工作运行在默认的工作队列上，并且它们有一些数据的依赖关系，那么很有可能会产生死锁。解决办法是为每一个可能产生死锁的工作创建一个专职的工作线程，这样又回到问题1了。
    

## 2 CMWQ 引入

为此社区专家Tejun Heo在Linux 2.6.36中提出了一套解决方案——并发托管工作队列（Concurrency-Managed Workqueue，CMWQ）。

![image.png|500](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2025/06/e3dfb2bb15699c1e0ef288922828b7e3.png)


- 执行工作任务的线程称为工作线程。
    
- 工作线程会串行化地执行挂载到队列中所有的工作。
    
- 如果队列中没有工作，那么该工作线程就会变成空闲状态。
    
- 为了管理众多工作线程，CMWQ提出了工作线程池（worker-pool）的概念，工作线程池有两种。
    
    - 一种是BOUND类型的，可以理解为Per-CPU类型，每个CPU都有工作线程池；
        
    - 另一种是UNBOUND类型的，即不和具体CPU绑定。这两种工作线程池都会定义两个线程池，一个给普通优先级的工作使用，另一个给高优先级的工作使用。这些工作线程池中的线程数量是动态分配和管理的，而不是固定的。当工作线程睡眠时，会检查是否需要唤醒更多的工作线程，如有需要，会唤醒同一个工作线程池中处于空闲状态的工作线程。
        

## 3 工作队列的相关数据结构


根据工作队列机制，最小的调度单元是工作项，有的书中称为工作任务，本章中简称为work，由work_struct数据结构来抽象和描述。

```C
workqueue_struct
  |
  +--> pool_workqueue
         |
         +--> worker_pool
                |
                +--> worker
                        |
                        +--> work_struct
```

![image.png|500](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2025/06/ae131fe433bcd364a8f6ea3d854b3b4d.png)


- work_struct：`work_struct` 是工作队列的核心结构，表示一个需要执行的工作任务。每一个工作任务都由 `work_struct` 表示，并被调度到 `worker` 中运行。
    
- workqueue_struct：`workqueue_struct` 是工作队列的核心管理结构，表示一个工作队列。工作队列可以是全局队列，也可以是用户自定义队列。
    
- worker：`worker` 是工作队列中实际执行任务的线程，每个 `worker` 对应一个内核线程，用来处理队列中的工作任务。
    
- worker_pool：`worker_pool` 是一个内核线程池，管理多个 `worker`，为 `workqueue_struct` 提供资源。它的引入是为了更高效地调度线程，并支持多队列共享资源。
    
- pool_workqueue：`pool_workqueue` 是连接 `workqueue_struct` 和 `worker_pool` 的桥梁，负责在两者之间建立联系，并分发任务到线程池中。
    

### 3.1 work_struct

```C
<include/linux/workqueue.h>
struct work_struct {
     atomic_long_t data;
     struct list_head entry;
     work_func_t func;
};
```

![image.png|500](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2025/06/b12358f715b40d16b58fd2db9bfcc350.png)


  

work_struct数据结构的定义比较简单。data成员包括两部分，低位部分是work的标志位，剩余的位通常用于存放上一次运行的worker_pool的ID或pool_workqueue的指针，存放的内容由WORK_STRUCT_PWQ标志位来决定。func是work的处理函数，entry用于把work挂到其他队列上。

### 3.2 worker

work运行在内核线程中，这个内核线程在代码中称为worker，worker类似于流水线中的工人，work类似于工人的工作。工作线程用worker数据结构来描述。

```C

<kernel/workqueue_internal.h>
struct worker {
     struct work_struct *current_work;
     work_func_t   current_func;
     struct pool_workqueue *current_pwq;
     struct list_head  scheduled;
     struct task_struct *task;
     struct worker_pool   *pool;
     int          id;
     struct list_head      node;
     ...
};
```

- current_work：当前正在处理的work。
    
- current_func：当前正在执行的work回调函数。
    
- current_pwq：当前work所属的pool_workqueue。
    
- scheduled：所有被调度并正准备执行的work都挂入该链表中。
    
- task：该工作线程的task_struct数据结构。
    
- pool：该工作线程所属的worker_pool。
    
- id：工作线程的ID。
    

### 3.3 worker_pool

CMWQ提出了工作线程池的概念，代码中使用worker_pool数据结构来抽象和描述。简化后的worker_pool数据结构如下。

```C
<kernel/workqueue.c>
struct worker_pool {
     spinlock_t     lock;
     int            cpu;
     int            node;
     int            id;
     unsigned int       flags;
     struct list_head   worklist;
     int            nr_workers;
     int            nr_idle;
     struct list_head   idle_list;
     struct list_head   workers;
     struct workqueue_attrs*attrs;
     atomic_t     nr_running ____cacheline_aligned_in_smp;
     struct rcu_head       rcu;
     ...
} ____cacheline_aligned_in_smp;
```

- lock：用于保护工作线程池的自旋锁。
    
- cpu：对于BOUND类型的工作队列，cpu表示绑定的CPU ID；对于UNBOUND类型的工作线程池，该值为−1。
    
- node：对于UNBOUND类型的工作队列，node表示该工作线程池所属内存节点的ID。
    
- id：该工作线程池的ID。
    
- worklist：处于pending状态的work会挂入该链表中。
    
- nr_workers：工作线程的数量。
    
- nr_idle：处于idle状态的工作线程的数量。
    
- idle_list：处于idle状态的工作线程会挂入该链表中。
    
- workers：该工作线程池管理的工作线程会挂入该链表中。
    
- attrs：工作线程的属性。
    
- nr_running：计数值，用于管理worker的创建和销毁，表示正在运行中的worker数量。在进程调度器中唤醒进程（使用try_to_wake_up()）时，其他CPU可能会同时访问该成员，该成员频繁在多核之间读写，因此让该成员独占一个缓冲行，避免多核CPU在读写该成员时引发其他临近的成员“颠簸”现象，这也是所谓的“缓存行伪共享”的问题。
    
- rcu：RCU锁。
    

工作线程池是Per-CPU类型的概念，每个CPU都有工作线程池。准确地说，每个CPU有两个工作线程池，一个用于普通优先级的工作线程，另一个用于高优先级的工作线程。

```C

<kernel/workqueue.c>
static DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);
```

### 3.4 pool_workqueue

CMWQ还定义了一个pool_workqueue数据结构，它是连接工作队列和工作线程池的枢纽。、

```C
<kernel/workqueue.c>
struct pool_workqueue {
     struct worker_pool    *pool;
     struct workqueue_struct *wq;
     int          nr_active;
     int          max_active;
     struct list_head  delayed_works;
     struct rcu_head       rcu;
     ...
} __aligned(1 << WORK_STRUCT_FLAG_BITS);
```

其中，WORK_STRUCT_FLAG_BITS为8，因此pool_workqueue数据结构是按照256字节对齐的，这样方便把该数据结构指针的Bit [8:31]位存放到work->data中，work->data字段的低8位用于存放一些标志位，详见set_work_pwq()函数和get_work_pwq()函数。

- pool：指向工作线程池指针。
    
- wq：指向所属的工作队列。
    
- nr_active：活跃的work数量。
    
- max_active：活跃的work最大数量。
    
- delayed_works：链表头，延迟执行的work可以挂入该链表。
    
- rcu：RCU锁。
    

### 3.5 workqueue_struct

系统中所有的工作队列（包括系统默认的工作队列，如system_wq或system_highpri_wq等，以及驱动开发者新创建的工作队列，共享一组工作线程池。

对于BOUND类型的工作队列，每个CPU只有两个工作线程池，每个工作线程池可以和多个工作队列对应，每个工作队列也只能对应这几个工作线程池。工作队列由workqueue_struct数据结构来描述。

```C
<kernel/workqueue.c>
struct workqueue_struct {
     struct list_head   pwqs;
     struct list_head   list;
     struct list_head   maydays;
     struct worker      *rescuer;
     struct workqueue_attrs*unbound_attrs;
     struct pool_workqueue*dfl_pwq;
     char         name[WQ_NAME_LEN];
     unsigned int    flags ____cacheline_aligned;
     struct pool_workqueue __percpu *cpu_pwqs;
     ...
};
```

- pwqs：所有的pool-workqueue数据结构都挂入链表中。
    
- list：链表节点。系统定义一个全局的链表工作队列，所有的工作队列挂入该链表。
    
- maydays：所有rescuer状态下的pool-workqueue数据结构挂入该链表。
    
- rescuer：rescuer工作线程。内存紧张时创建新的工作线程可能会失败，如果创建工作队列时设置了WQ_MEM_RECLAIM标志位，那么rescuer工作线程会接管这种情况。
    
- unbound_attrs：UNBOUND类型的属性。
    
- dfl_pwq：指向UNBOUND类型的pool_workqueue。
    
- name：该工作队列的名字。
    
- flags：标志位经常被不同CPU访问，因此要和缓存行对齐。标志位包括WQ_UNBOUND、WQ_HIGHPRI、WQ_FREEZABLE等。
    
- cpu_pwqs：指向Per-CPU类型的pool_workqueue。

## 4 工作队列的四种状态

共享工作队列：（CPU）

- INIT_WORK （初始化）
    
- schedule_work（把任务发给内核创建的队列）
    
自定义工作队列（CPU）

- create_workqueue （创建一个队列）
    
- INIT_WORK(初始化)
    
- queue_work（把任务发给自己创建的队列）
    
延迟工作（CPU）

- create_workqueue（创建一个队列）
    
- INIT_DELAYED_WORK（在INIT_WORK基础上增加一个延时）
    
- queue_delayed_work（把任务发给自己创建的队列，并告知延后时间）
    
- 或者schedule_delayed_work（调用这个就没有第一步了，并告知延后时间）


并发工作队列（不绑定CPU）

- alloc_workqueue
    
- INIT_WORK(初始化)
    
- queue_work（把任务发给自己创建的队列）