---
æ–‡ç« æ ‡é¢˜: "[[8_Linuxç³»ç»Ÿè½¯ä»¶å®‰è£…-2]]" 
æ–‡ç« ä½œè€…: Dakkk
æ–‡ç« æ¦‚è¦: |
  ä»‹ç»Linuxé›†ç¾¤åŒ–ç¯å¢ƒéƒ¨ç½²ï¼ŒåŒ…æ‹¬å¤šå°è™šæ‹Ÿæœºé…ç½®ã€ä¸»æœºåæ˜ å°„ã€SSHå…å¯†ç™»å½•ï¼Œä»¥åŠZookeeperã€Kafkaã€Hadoopã€HBaseã€Sparkã€Flinkç­‰å¤§æ•°æ®ç»„ä»¶çš„é›†ç¾¤å®‰è£…éƒ¨ç½²æ–¹æ³•ã€‚
tags:
- "Linuxé›†ç¾¤"
- "Hadoop"
- "Zookeeper"
- "Kafka"
- "HBase"
- "Spark"
- "Flink"
- "å¤§æ•°æ®"
- "åˆ†å¸ƒå¼éƒ¨ç½²"
ç›¸å…³æ–‡ç« : æš‚æ—  ğŸ¤·
æ–‡ç« åˆ†ç±»: "ğŸ§ Linuxç³»ç»Ÿ"
æ–‡ç« è·¯å¾„: "06-ğŸ§ Linuxç³»ç»Ÿ/02-âš™ï¸ ç³»ç»ŸåŸºç¡€/01-ğŸ’» å‘½ä»¤è¡Œæ“ä½œ/8_Linuxç³»ç»Ÿè½¯ä»¶å®‰è£…-2.md"
æ–‡ç« éš¾åº¦: ä¸­çº§ ğŸŒ³
ç›®å‰é˜¶æ®µ: âœ… å·²å®Œæˆ
é‡è¦æ€§: â­â­â­â­ æ ¸å¿ƒèƒ½åŠ›
åˆ›å»ºæ—¶é—´: 2024-08-11 18:15:12
ä¿®æ”¹æ—¶é—´: 2025-05-28 00:19:51
---


## 1 é›†ç¾¤åŒ–ç¯å¢ƒå‰ç½®å‡†å¤‡

### 1.1 ä»‹ç»

åœ¨å‰é¢ï¼Œæˆ‘ä»¬æ‰€å­¦ä¹ å®‰è£…çš„è½¯ä»¶ï¼Œéƒ½æ˜¯ä»¥å•æœºæ¨¡å¼è¿è¡Œçš„ã€‚

åç»­ï¼Œæˆ‘ä»¬å°†è¦å­¦ä¹ å¤§æ•°æ®ç›¸å…³çš„è½¯ä»¶éƒ¨ç½²ï¼Œæ‰€ä»¥åç»­æˆ‘ä»¬æ‰€å®‰è£…çš„è½¯ä»¶æœåŠ¡ï¼Œå¤§å¤šæ•°éƒ½æ˜¯ä»¥é›†ç¾¤åŒ–ï¼ˆå¤šå°æœåŠ¡å™¨å…±åŒå·¥ä½œï¼‰æ¨¡å¼è¿è¡Œçš„ã€‚


æ‰€ä»¥ï¼Œåœ¨å½“å‰å°èŠ‚ï¼Œæˆ‘ä»¬éœ€è¦å®Œæˆé›†ç¾¤åŒ–ç¯å¢ƒçš„å‰ç½®å‡†å¤‡ï¼ŒåŒ…æ‹¬åˆ›å»ºå¤šå°è™šæ‹Ÿæœºï¼Œé…ç½®ä¸»æœºåæ˜ å°„ï¼ŒSSHå…å¯†ç™»å½•ç­‰ç­‰ã€‚
### 1.2 éƒ¨ç½²

#### 1.2.1 é…ç½®å¤šå°Linuxè™šæ‹Ÿæœº

å®‰è£…é›†ç¾¤åŒ–è½¯ä»¶ï¼Œé¦–è¦æ¡ä»¶å°±æ˜¯è¦æœ‰å¤šå°LinuxæœåŠ¡å™¨å¯ç”¨ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨VMwareæä¾›çš„å…‹éš†åŠŸèƒ½ï¼Œå°†æˆ‘ä»¬çš„è™šæ‹Ÿæœºé¢å¤–å…‹éš†å‡º3å°æ¥ä½¿ç”¨ã€‚

1. é¦–å…ˆï¼Œå…³æœºå½“å‰CentOSç³»ç»Ÿè™šæ‹Ÿæœºï¼ˆå¯ä»¥ä½¿ç”¨rootç”¨æˆ·æ‰§è¡Œ`init 0`æ¥å¿«é€Ÿå…³æœºï¼‰

2. æ–°å»ºæ–‡ä»¶å¤¹![image-20221025104157628|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/b7137992fe7cca8d2f800184da94d28b.png)

   æ–‡ä»¶å¤¹èµ·åä¸ºï¼š`è™šæ‹Ÿæœºé›†ç¾¤`

3. å…‹éš†![image-20221025104131303|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/61961c2ea65382951a892e1436a626a9.png)

   ![image-20221025104312091|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/5340b621dfdd01cb82d1e274081c2f1b.png)

   ![image-20221025104329109|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/c975da69610bf8b7fe445ba3b1d64ace.png)

   ![image-20221025104345484|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/2d546c21ea4bfef789afdc2778cc61d3.png)

   ![image-20221025104414576|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/57ddbe0400f1301ec738e76880d71cb3.png)

   ![image-20221025104427160|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/77e8e91f20fc0526a2c8c8ca9999e4ed.png)

   ![image-20221025104432927|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/a3e50d7e959f51b4e8a4f06ccfe13df1.png)

   ![image-20221025104446044|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/144fb6ff63fed2658d08fc5d68ca1a6d.png)

4. åŒæ ·çš„æ“ä½œå…‹éš†å‡ºï¼šnode2å’Œnode3

   ![image-20221025104825204|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/2ad0f322fccea6fe2618be034753852f.png)

5. å¼€å¯node1ï¼Œä¿®æ”¹ä¸»æœºåä¸ºnode1ï¼Œå¹¶ä¿®æ”¹å›ºå®šipä¸ºï¼š192.168.88.131

   ```shell
   # ä¿®æ”¹ä¸»æœºå
   hostnamectl set-hostname node1
   
   # ä¿®æ”¹IPåœ°å€
   vim /etc/sysconfig/network-scripts/ifcfg-ens33
   IPADDR="192.168.88.131"
   
   # é‡å¯ç½‘å¡
   systemctl stop network
   systemctl start network
   # æˆ–è€…ç›´æ¥
   systemctl restart network
   ```

6. åŒæ ·çš„æ“ä½œå¯åŠ¨node2å’Œnode3,

   ä¿®æ”¹node2ä¸»æœºåä¸ºnode2ï¼Œè®¾ç½®ipä¸º192.168.88.132

   ä¿®æ”¹node2ä¸»æœºåä¸ºnode3ï¼Œè®¾ç½®ipä¸º192.168.88.133

7. é…ç½®FinalShellï¼Œé…ç½®è¿æ¥åˆ°node1ã€node2ã€node3çš„è¿æ¥

   > ä¸ºäº†ç®€å•èµ·è§ï¼Œå»ºè®®é…ç½®rootç”¨æˆ·ç™»å½•



#### 1.2.2 å‡†å¤‡ä¸»æœºåæ˜ å°„

1. åœ¨Windowsç³»ç»Ÿä¸­ä¿®æ”¹hostsæ–‡ä»¶ï¼Œå¡«å…¥å¦‚ä¸‹å†…å®¹ï¼š

   > å¦‚æœåŒå­¦ä»¬ä½¿ç”¨MacOSç³»ç»Ÿï¼Œè¯·ï¼š
   >
   > 1. sudo su -ï¼Œåˆ‡æ¢åˆ°root
   > 2. ä¿®æ”¹/etc/hostsæ–‡ä»¶

   ```shell
   192.168.88.131 node1
   192.168.88.132 node2
   192.168.88.133 node3
   ```

2. åœ¨3å°Linuxçš„/etc/hostsæ–‡ä»¶ä¸­ï¼Œå¡«å…¥å¦‚ä¸‹å†…å®¹ï¼ˆ==3å°éƒ½è¦æ·»åŠ ==ï¼‰

   ```shell
   192.168.88.131 node1
   192.168.88.132 node2
   192.168.88.133 node3
   ```



#### 1.2.3 é…ç½®SSHå…å¯†ç™»å½•

##### 1.2.3.1 ç®€ä»‹

SSHæœåŠ¡æ˜¯ä¸€ç§ç”¨äºè¿œç¨‹ç™»å½•çš„å®‰å…¨è®¤è¯åè®®ã€‚

æˆ‘ä»¬é€šè¿‡FinalShellè¿œç¨‹è¿æ¥åˆ°Linuxï¼Œå°±æ˜¯ä½¿ç”¨çš„SSHæœåŠ¡ã€‚

SSHæœåŠ¡æ”¯æŒï¼š

1. é€šè¿‡è´¦æˆ·+å¯†ç çš„è®¤è¯æ–¹å¼æ¥åšç”¨æˆ·è®¤è¯
2. é€šè¿‡è´¦æˆ·+ç§˜é’¥æ–‡ä»¶çš„æ–¹å¼åšç”¨æˆ·è®¤è¯



SSHå¯ä»¥è®©æˆ‘ä»¬é€šè¿‡SSHå‘½ä»¤ï¼Œè¿œç¨‹çš„ç™»é™†åˆ°å…¶å®ƒçš„ä¸»æœºä¸Šï¼Œæ¯”å¦‚ï¼š

åœ¨node1æ‰§è¡Œï¼šssh root@node2ï¼Œå°†ä»¥rootç”¨æˆ·ç™»å½•node2æœåŠ¡å™¨ï¼Œè¾“å…¥å¯†ç å³å¯æˆåŠŸç™»é™†

æˆ–è€…ssh node2ï¼Œå°†ä»¥å½“å‰ç”¨æˆ·ç›´æ¥ç™»é™†åˆ°node2æœåŠ¡å™¨ã€‚



##### 1.2.3.2 SSHå…å¯†é…ç½®

åç»­å®‰è£…çš„é›†ç¾¤åŒ–è½¯ä»¶ï¼Œå¤šæ•°éœ€è¦è¿œç¨‹ç™»å½•ä»¥åŠè¿œç¨‹æ‰§è¡Œå‘½ä»¤ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•èµ·è§ï¼Œé…ç½®ä¸‰å°LinuxæœåŠ¡å™¨ä¹‹é—´çš„å…å¯†ç äº’ç›¸SSHç™»é™†

1. åœ¨æ¯ä¸€å°æœºå™¨éƒ½æ‰§è¡Œï¼š`ssh-keygen -t rsa -b 4096`ï¼Œä¸€è·¯å›è½¦åˆ°åº•å³å¯

2. åœ¨æ¯ä¸€å°æœºå™¨éƒ½æ‰§è¡Œï¼š

   ```shell
   ssh-copy-id node1
   ssh-copy-id node2
   ssh-copy-id node3
   ```

3. æ‰§è¡Œå®Œæ¯•åï¼Œnode1ã€node2ã€node3ä¹‹é—´å°†å®Œæˆrootç”¨æˆ·ä¹‹é—´çš„å…å¯†äº’é€š

#### 1.2.4 é…ç½®JDKç¯å¢ƒ

åç»­çš„å¤§æ•°æ®é›†ç¾¤è½¯ä»¶ï¼Œå¤šæ•°æ˜¯éœ€è¦Javaè¿è¡Œç¯å¢ƒçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸º==æ¯ä¸€å°==æœºå™¨éƒ½é…ç½®JDKç¯å¢ƒã€‚

JDKé…ç½®å‚é˜…ï¼š`Tomcat`å®‰è£…éƒ¨ç½²ç¯èŠ‚ã€‚

#### 1.2.5 å…³é—­é˜²ç«å¢™å’ŒSELinux

é›†ç¾¤åŒ–è½¯ä»¶ä¹‹é—´éœ€è¦é€šè¿‡ç«¯å£äº’ç›¸é€šè®¯ï¼Œä¸ºäº†é¿å…å‡ºç°ç½‘ç»œä¸é€šçš„é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•çš„åœ¨é›†ç¾¤å†…éƒ¨å…³é—­é˜²ç«å¢™ã€‚

==åœ¨æ¯ä¸€å°æœºå™¨éƒ½æ‰§è¡Œ==

```shell
systemctl stop firewalld
systemctl disable firewalld
```



Linuxæœ‰ä¸€ä¸ªå®‰å…¨æ¨¡å—ï¼šSELinuxï¼Œç”¨ä»¥é™åˆ¶ç”¨æˆ·å’Œç¨‹åºçš„ç›¸å…³æƒé™ï¼Œæ¥ç¡®ä¿ç³»ç»Ÿçš„å®‰å…¨ç¨³å®šã€‚

SELinuxçš„é…ç½®åŒé˜²ç«å¢™ä¸€æ ·ï¼Œéå¸¸å¤æ‚ï¼Œè¯¾ç¨‹ä¸­ä¸å¤šæ¶‰åŠï¼Œåç»­è§†æƒ…å†µå¯ä»¥å‡ºä¸€ç« SELinuxçš„é…ç½®è¯¾ç¨‹ã€‚

åœ¨å½“å‰ï¼Œæˆ‘ä»¬åªéœ€è¦å…³é—­SELinuxåŠŸèƒ½ï¼Œé¿å…å¯¼è‡´åé¢çš„è½¯ä»¶è¿è¡Œå‡ºç°é—®é¢˜å³å¯ï¼Œ

==åœ¨æ¯ä¸€å°æœºå™¨éƒ½æ‰§è¡Œ==

```shell
vim /etc/sysconfig/selinux

# å°†ç¬¬ä¸ƒè¡Œï¼ŒSELINUX=enforcing æ”¹ä¸º
SELINUX=disabled
# ä¿å­˜é€€å‡ºåï¼Œé‡å¯è™šæ‹Ÿæœºå³å¯ï¼Œåƒä¸‡è¦æ³¨æ„disabledå•è¯ä¸è¦å†™é”™ï¼Œä¸ç„¶æ— æ³•å¯åŠ¨ç³»ç»Ÿ
```

#### 1.2.6 æ·»åŠ å¿«ç…§

ä¸ºäº†é¿å…åç»­å‡ºç°é—®é¢˜ï¼Œåœ¨å®Œæˆä¸Šè¿°è®¾ç½®åï¼Œä¸º==æ¯ä¸€å°è™šæ‹Ÿæœº==éƒ½åˆ¶ä½œå¿«ç…§ï¼Œç•™å¾…ä½¿ç”¨ã€‚
### 1.3 è¡¥å……å‘½ä»¤ - scp

åç»­çš„å®‰è£…éƒ¨ç½²æ“ä½œï¼Œæˆ‘ä»¬å°†ä¼šé¢‘ç¹çš„åœ¨å¤šå°æœåŠ¡å™¨ä¹‹é—´ç›¸äº’ä¼ è¾“æ•°æ®ã€‚

ä¸ºäº†æ›´åŠ æ–¹é¢çš„äº’ç›¸ä¼ è¾“ï¼Œæˆ‘ä»¬è¡¥å……ä¸€ä¸ªå‘½ä»¤ï¼šscp

scpå‘½ä»¤æ˜¯cpå‘½ä»¤çš„å‡çº§ç‰ˆï¼Œå³ï¼šssh cpï¼Œé€šè¿‡SSHåè®®å®Œæˆæ–‡ä»¶çš„å¤åˆ¶ã€‚

å…¶ä¸»è¦çš„åŠŸèƒ½å°±æ˜¯ï¼šåœ¨ä¸åŒçš„LinuxæœåŠ¡å™¨ä¹‹é—´ï¼Œé€šè¿‡`SSH`åè®®äº’ç›¸ä¼ è¾“æ–‡ä»¶ã€‚

åªè¦çŸ¥æ™“æœåŠ¡å™¨çš„è´¦æˆ·å’Œå¯†ç ï¼ˆæˆ–å¯†é’¥ï¼‰ï¼Œå³å¯é€šè¿‡SCPäº’ä¼ æ–‡ä»¶ã€‚


è¯­æ³•ï¼š
```shell
scp [-r] å‚æ•°1 å‚æ•°2
- -ré€‰é¡¹ç”¨äºå¤åˆ¶æ–‡ä»¶å¤¹ä½¿ç”¨ï¼Œå¦‚æœå¤åˆ¶æ–‡ä»¶å¤¹ï¼Œå¿…é¡»ä½¿ç”¨-r
- å‚æ•°1ï¼šæœ¬æœºè·¯å¾„ æˆ– è¿œç¨‹ç›®æ ‡è·¯å¾„
- å‚æ•°2ï¼šè¿œç¨‹ç›®æ ‡è·¯å¾„ æˆ– æœ¬æœºè·¯å¾„

å¦‚ï¼š
scp -r /export/server/jdk root@node2:/export/server/
å°†æœ¬æœºä¸Šçš„jdkæ–‡ä»¶å¤¹ï¼Œ ä»¥rootçš„èº«ä»½å¤åˆ¶åˆ°node2çš„/export/server/å†…
åŒSSHç™»é™†ä¸€æ ·ï¼Œè´¦æˆ·åå¯ä»¥çœç•¥ï¼ˆä½¿ç”¨æœ¬æœºå½“å‰çš„åŒåè´¦æˆ·ç™»é™†ï¼‰

å¦‚ï¼š
scp -r node2:/export/server/jdk /export/server/
å°†è¿œç¨‹node2çš„jdkæ–‡ä»¶å¤¹ï¼Œå¤åˆ¶åˆ°æœ¬æœºçš„/export/server/å†…


# scpå‘½ä»¤çš„é«˜çº§ç”¨æ³•
cd /export/server
scp -r jdk node2:`pwd`/    # å°†æœ¬æœºå½“å‰è·¯å¾„çš„jdkæ–‡ä»¶å¤¹ï¼Œå¤åˆ¶åˆ°node2æœåŠ¡å™¨çš„åŒåè·¯å¾„ä¸‹
scp -r jdk node2:$PWD      # å°†æœ¬æœºå½“å‰è·¯å¾„çš„jdkæ–‡ä»¶å¤¹ï¼Œå¤åˆ¶åˆ°node2æœåŠ¡å™¨çš„åŒåè·¯å¾„ä¸‹
```

## 2 Zookeeperé›†ç¾¤å®‰è£…éƒ¨ç½²

### 2.1 ç®€ä»‹

ZooKeeperæ˜¯ä¸€ä¸ª[åˆ†å¸ƒå¼](https://baike.baidu.com/item/åˆ†å¸ƒå¼/19276232?fromModule=lemma_inlink)çš„ï¼Œå¼€æ”¾æºç çš„[åˆ†å¸ƒå¼åº”ç”¨ç¨‹åº](https://baike.baidu.com/item/åˆ†å¸ƒå¼åº”ç”¨ç¨‹åº/9854429?fromModule=lemma_inlink)åè°ƒæœåŠ¡ï¼Œæ˜¯Hadoopå’Œ[Hbase](https://baike.baidu.com/item/Hbase/7670213?fromModule=lemma_inlink)çš„é‡è¦ç»„ä»¶ã€‚å®ƒæ˜¯ä¸€ä¸ªä¸ºåˆ†å¸ƒå¼åº”ç”¨æä¾›ä¸€è‡´æ€§æœåŠ¡çš„è½¯ä»¶ï¼Œæä¾›çš„åŠŸèƒ½åŒ…æ‹¬ï¼šé…ç½®ç»´æŠ¤ã€åŸŸåæœåŠ¡ã€åˆ†å¸ƒå¼åŒæ­¥ã€ç»„æœåŠ¡ç­‰ã€‚

é™¤äº†ä¸ºHadoopå’ŒHBaseæä¾›åè°ƒæœåŠ¡å¤–ï¼ŒZookeeperä¹Ÿè¢«å…¶å®ƒè®¸å¤šè½¯ä»¶é‡‡ç”¨ä½œä¸ºå…¶åˆ†å¸ƒå¼çŠ¶æ€ä¸€è‡´æ€§çš„ä¾èµ–ï¼Œæ¯”å¦‚Kafkaï¼Œåˆæˆ–è€…ä¸€äº›è½¯ä»¶é¡¹ç›®ä¸­ï¼Œä¹Ÿç»å¸¸èƒ½è§åˆ°Zookeeperä½œä¸ºä¸€è‡´æ€§åè°ƒæœåŠ¡å­˜åœ¨ã€‚

Zookeeperä¸è®ºæ˜¯å¤§æ•°æ®é¢†åŸŸäº¦æˆ–æ˜¯å…¶å®ƒæœåŠ¡å™¨å¼€å‘é¢†åŸŸï¼Œæ¶‰åŠåˆ°åˆ†å¸ƒå¼çŠ¶æ€ä¸€è‡´æ€§çš„åœºæ™¯ï¼Œæ€»æœ‰å®ƒçš„èº«å½±å­˜åœ¨ã€‚

### 2.2 å®‰è£…

Zookeeperæ˜¯ä¸€æ¬¾åˆ†å¸ƒå¼çš„é›†ç¾¤åŒ–è½¯ä»¶ï¼Œå¯ä»¥åœ¨å¤šå°æœåŠ¡å™¨ä¸Šéƒ¨ç½²ï¼Œå¹¶ååŒç»„æˆåˆ†å¸ƒå¼é›†ç¾¤ä¸€èµ·å·¥ä½œã€‚



1. é¦–å…ˆï¼Œè¦ç¡®ä¿å·²ç»å®Œæˆäº†`é›†ç¾¤åŒ–ç¯å¢ƒå‰ç½®å‡†å¤‡`ç¯èŠ‚çš„å…¨éƒ¨å†…å®¹

2. ã€node1ä¸Šæ“ä½œã€‘ä¸‹è½½Zookeeperå®‰è£…åŒ…ï¼Œå¹¶è§£å‹

   ```shell
   # ä¸‹è½½
   wget http://archive.apache.org/dist/zookeeper/zookeeper-3.5.9/apache-zookeeper-3.5.9-bin.tar.gz
   
   # ç¡®ä¿å¦‚ä¸‹ç›®å½•å­˜åœ¨ï¼Œä¸å­˜åœ¨å°±åˆ›å»º
   mkdir -p /export/server
   
   # è§£å‹
   tar -zxvf apache-zookeeper-3.5.9-bin.tar.gz -C /export/server
   ```

3. ã€node1ä¸Šæ“ä½œã€‘åˆ›å»ºè½¯é“¾æ¥

   ```shell
   ln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper
   ```

4. ã€node1ä¸Šæ“ä½œã€‘ä¿®æ”¹é…ç½®æ–‡ä»¶

   ```shell
   vim /export/server/zookeeper/conf/zoo.cfg
   
   tickTime=2000
   # zookeeperæ•°æ®å­˜å‚¨ç›®å½•
   dataDir=/export/server/zookeeper/data
   clientPort=2181
   initLimit=5
   syncLimit=2
   server.1=node1:2888:3888
   server.2=node2:2888:3888
   server.3=node3:2888:3888
   ```

5. ã€node1ä¸Šæ“ä½œã€‘é…ç½®`myid`

   ```shell
   # 1. åˆ›å»ºZookeeperçš„æ•°æ®ç›®å½•
   mkdir /export/server/zookeeper/data
   
   # 2. åˆ›å»ºæ–‡ä»¶ï¼Œå¹¶å¡«å…¥1
   vim /export/server/zookeeper/data/myid
   # åœ¨æ–‡ä»¶å†…å¡«å…¥1å³å¯
   ```

6. ã€åœ¨node2å’Œnode3ä¸Šæ“ä½œã€‘ï¼Œåˆ›å»ºæ–‡ä»¶å¤¹

   ```shell
   mkdir -p /export/server
   ```

7. ã€node1ä¸Šæ“ä½œã€‘å°†Zookeeper å¤åˆ¶åˆ°node2å’Œnode3

   ```shell
   cd /export/server
   
   scp -r apache-zookeeper-3.5.9 node2:`pwd`/
   scp -r apache-zookeeper-3.5.9 node3:`pwd`/
   ```

8. ã€åœ¨node2ä¸Šæ“ä½œã€‘

   ```shell
   # 1. åˆ›å»ºè½¯é“¾æ¥
   ln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper
   
   # 2. ä¿®æ”¹myidæ–‡ä»¶
   vim /export/server/zookeeper/data/myid
   # ä¿®æ”¹å†…å®¹ä¸º2
   ```

9. ã€åœ¨node3ä¸Šæ“ä½œã€‘

   ```shell
   # 1. åˆ›å»ºè½¯é“¾æ¥
   ln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper
   
   # 2. ä¿®æ”¹myidæ–‡ä»¶
   vim /export/server/zookeeper/data/myid
   # ä¿®æ”¹å†…å®¹ä¸º3
   ```

10. ã€åœ¨node1ã€node2ã€node3ä¸Šåˆ†åˆ«æ‰§è¡Œã€‘å¯åŠ¨Zookeeper

    ```shell
    # å¯åŠ¨å‘½ä»¤
    /export/server/zookeeper/bin/zkServer.sh start		# å¯åŠ¨Zookeeper
    ```

11. ã€åœ¨node1ã€node2ã€node3ä¸Šåˆ†åˆ«æ‰§è¡Œã€‘æ£€æŸ¥Zookeeperè¿›ç¨‹æ˜¯å¦å¯åŠ¨

    ```shell
    jps
    
    # ç»“æœä¸­æ‰¾åˆ°æœ‰ï¼šQuorumPeerMain è¿›ç¨‹å³å¯
    ```

12. ã€node1ä¸Šæ“ä½œã€‘éªŒè¯Zookeeper

    ```shell
    /export/server/zookeeper/zkCli.sh
    
    # è¿›å…¥åˆ°Zookeeperæ§åˆ¶å°ä¸­åï¼Œæ‰§è¡Œ
    ls /
    
    # å¦‚æ— æŠ¥é”™å³é…ç½®æˆåŠŸ
    ```

è‡³æ­¤Zookeeperå®‰è£…å®Œæˆ

## 3 Kafkaé›†ç¾¤å®‰è£…éƒ¨ç½²

### 3.1 ç®€ä»‹

Kafkaæ˜¯ä¸€æ¬¾`åˆ†å¸ƒå¼çš„ã€å»ä¸­å¿ƒåŒ–çš„ã€é«˜ååä½å»¶è¿Ÿã€è®¢é˜…æ¨¡å¼`çš„æ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿã€‚

åŒRabbitMQä¸€æ ·ï¼ŒKafkaä¹Ÿæ˜¯æ¶ˆæ¯é˜Ÿåˆ—ã€‚ä¸è¿‡RabbitMQå¤šç”¨äºåç«¯ç³»ç»Ÿï¼Œå› å…¶æ›´åŠ ä¸“æ³¨äºæ¶ˆæ¯çš„å»¶è¿Ÿå’Œå®¹é”™ã€‚

Kafkaå¤šç”¨äºå¤§æ•°æ®ä½“ç³»ï¼Œå› å…¶æ›´åŠ ä¸“æ³¨äºæ•°æ®çš„ååèƒ½åŠ›ã€‚

Kafkaå¤šæ•°éƒ½æ˜¯è¿è¡Œåœ¨åˆ†å¸ƒå¼ï¼ˆé›†ç¾¤åŒ–ï¼‰æ¨¡å¼ä¸‹ï¼Œæ‰€ä»¥è¯¾ç¨‹å°†ä»¥3å°æœåŠ¡å™¨ï¼Œæ¥å®ŒæˆKafkaé›†ç¾¤çš„å®‰è£…éƒ¨ç½²ã€‚

### 3.2 å®‰è£…

1. ç¡®ä¿å·²ç»è·Ÿéšå‰é¢çš„è§†é¢‘ï¼Œå®‰è£…å¹¶éƒ¨ç½²äº†JDKå’ŒZookeeperæœåŠ¡
   > Kafkaçš„è¿è¡Œä¾èµ–JDKç¯å¢ƒå’ŒZookeeperè¯·ç¡®ä¿å·²ç»æœ‰äº†JDKç¯å¢ƒå’ŒZookeeper

2. ã€åœ¨node1æ“ä½œã€‘ä¸‹è½½å¹¶ä¸Šä¼ Kafkaçš„å®‰è£…åŒ…
   ```shell
   # ä¸‹è½½å®‰è£…åŒ…
   wget http://archive.apache.org/dist/kafka/2.4.1/kafka_2.12-2.4.1.tgz
   ```

3. ã€åœ¨node1æ“ä½œã€‘è§£å‹
   ```shell
   mkdir -p /export/server			# æ­¤æ–‡ä»¶å¤¹å¦‚æœä¸å­˜åœ¨éœ€å…ˆåˆ›å»º
   
   # è§£å‹
   tar -zxvf kafka_2.12-2.4.1.tgz -C /export/server/
   
   # åˆ›å»ºè½¯é“¾æ¥
   ln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka
   ```

4. ã€åœ¨node1æ“ä½œã€‘ä¿®æ”¹Kafkaç›®å½•å†…çš„configç›®å½•å†…çš„`server.properties`æ–‡ä»¶

   ````shell
   cd /export/server/kafka/config
   # æŒ‡å®šbrokerçš„id
   broker.id=1
   # æŒ‡å®š kafkaçš„ç»‘å®šç›‘å¬çš„åœ°å€
   listeners=PLAINTEXT://node1:9092
   # æŒ‡å®šKafkaæ•°æ®çš„ä½ç½®
   log.dirs=/export/server/kafka/data
   # æŒ‡å®šZookeeperçš„ä¸‰ä¸ªèŠ‚ç‚¹
   zookeeper.connect=node1:2181,node2:2181,node3:2181
   ````

5. ã€åœ¨node1æ“ä½œã€‘å°†node1çš„kafkaå¤åˆ¶åˆ°node2å’Œnode3

   ```shell
   cd /export/server
   
   # å¤åˆ¶åˆ°node2åŒåæ–‡ä»¶å¤¹
   scp -r kafka_2.12-2.4.1 node2:`pwd`/
   # å¤åˆ¶åˆ°node3åŒåæ–‡ä»¶å¤¹
   scp -r kafka_2.12-2.4.1 node3:$PWD
   ```

6. ã€åœ¨node2æ“ä½œã€‘

   ```shell
   # åˆ›å»ºè½¯é“¾æ¥
   ln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka
   
   cd /export/server/kafka/config
   # æŒ‡å®šbrokerçš„id
   broker.id=2
   # æŒ‡å®š kafkaçš„ç»‘å®šç›‘å¬çš„åœ°å€
   listeners=PLAINTEXT://node2:9092
   # æŒ‡å®šKafkaæ•°æ®çš„ä½ç½®
   log.dirs=/export/server/kafka/data
   # æŒ‡å®šZookeeperçš„ä¸‰ä¸ªèŠ‚ç‚¹
   zookeeper.connect=node1:2181,node2:2181,node3:2181
   ```

7. ã€åœ¨node3æ“ä½œã€‘

   ```shell
   # åˆ›å»ºè½¯é“¾æ¥
   ln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka
   
   cd /export/server/kafka/config
   # æŒ‡å®šbrokerçš„id
   broker.id=3
   # æŒ‡å®š kafkaçš„ç»‘å®šç›‘å¬çš„åœ°å€
   listeners=PLAINTEXT://node3:9092
   # æŒ‡å®šKafkaæ•°æ®çš„ä½ç½®
   log.dirs=/export/server/kafka/data
   # æŒ‡å®šZookeeperçš„ä¸‰ä¸ªèŠ‚ç‚¹
   zookeeper.connect=node1:2181,node2:2181,node3:2181
   ```

8. å¯åŠ¨kafka

   ```shell
   # è¯·å…ˆç¡®ä¿Zookeeperå·²ç»å¯åŠ¨äº†
   
   # æ–¹å¼1ï¼šã€å‰å°å¯åŠ¨ã€‘åˆ†åˆ«åœ¨node1ã€2ã€3ä¸Šæ‰§è¡Œå¦‚ä¸‹è¯­å¥
   /export/server/kafka/bin/kafka-server-start.sh /export/server/kafka/config/server.properties
   
   # æ–¹å¼2ï¼šã€åå°å¯åŠ¨ã€‘åˆ†åˆ«åœ¨node1ã€2ã€3ä¸Šæ‰§è¡Œå¦‚ä¸‹è¯­å¥
   nohup /export/server/kafka/bin/kafka-server-start.sh /export/server/kafka/config/server.properties 2>&1 >> /export/server/kafka/kafka-server.log &
   ```

9. éªŒè¯Kafkaå¯åŠ¨

   ```shell
   # åœ¨æ¯ä¸€å°æœåŠ¡å™¨æ‰§è¡Œ
   jps
   ```

   ![image-20221025174522487|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/7331c3c3ca3fe71e62296736ae5a86e1.png)
### 3.3 æµ‹è¯•Kafkaèƒ½å¦æ­£å¸¸ä½¿ç”¨

1. åˆ›å»ºæµ‹è¯•ä¸»é¢˜
```shell
# åœ¨node1æ‰§è¡Œï¼Œåˆ›å»ºä¸€ä¸ªä¸»é¢˜
/export/server/kafka_2.12-2.4.1/bin/kafka-topics.sh --create --zookeeper node1:2181 --replication-factor 1 --partitions 3 --topic test
```

2. è¿è¡Œæµ‹è¯•ï¼Œè¯·åœ¨FinalShellä¸­æ‰“å¼€2ä¸ªnode1çš„ç»ˆç«¯é¡µé¢
```shell
# æ‰“å¼€ä¸€ä¸ªç»ˆç«¯é¡µé¢ï¼Œå¯åŠ¨ä¸€ä¸ªæ¨¡æ‹Ÿçš„æ•°æ®ç”Ÿäº§è€…
/export/server/kafka_2.12-2.4.1/bin/kafka-console-producer.sh --broker-list node1:9092 --topic test
# å†æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯é¡µé¢ï¼Œåœ¨å¯åŠ¨ä¸€ä¸ªæ¨¡æ‹Ÿçš„æ•°æ®æ¶ˆè´¹è€…
/export/server/kafka_2.12-2.4.1/bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic test --from-beginning
```

## 4 å¤§æ•°æ®é›†ç¾¤ï¼ˆHadoopç”Ÿæ€ï¼‰å®‰è£…éƒ¨ç½²

### 4.1 ç®€ä»‹

1ï¼‰Hadoopæ˜¯ä¸€ä¸ªç”±ApacheåŸºé‡‘ä¼šæ‰€å¼€å‘çš„åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€æ¶æ„ã€‚
2ï¼‰ä¸»è¦è§£å†³ï¼Œæµ·é‡æ•°æ®çš„å­˜å‚¨å’Œæµ·é‡æ•°æ®çš„åˆ†æè®¡ç®—é—®é¢˜ã€‚

Hadoop HDFS æä¾›åˆ†å¸ƒå¼æµ·é‡æ•°æ®å­˜å‚¨èƒ½åŠ›

Hadoop YARN æä¾›åˆ†å¸ƒå¼é›†ç¾¤èµ„æºç®¡ç†èƒ½åŠ›

Hadoop MapReduce æä¾›åˆ†å¸ƒå¼æµ·é‡æ•°æ®è®¡ç®—èƒ½åŠ›

#### 4.1.1 å‰ç½®è¦æ±‚

- è¯·ç¡®ä¿å®Œæˆäº†é›†ç¾¤åŒ–ç¯å¢ƒå‰ç½®å‡†å¤‡ç« èŠ‚çš„å†…å®¹
- å³ï¼šJDKã€SSHå…å¯†ã€å…³é—­é˜²ç«å¢™ã€é…ç½®ä¸»æœºåæ˜ å°„ç­‰å‰ç½®æ“ä½œ

#### 4.1.2 Hadoopé›†ç¾¤è§’è‰²

Hadoopç”Ÿæ€ä½“ç³»ä¸­æ€»å…±ä¼šå‡ºç°å¦‚ä¸‹è¿›ç¨‹è§’è‰²ï¼š

1. Hadoop HDFSçš„ç®¡ç†è§’è‰²ï¼šNamenodeè¿›ç¨‹ï¼ˆ`ä»…éœ€1ä¸ªå³å¯ï¼ˆç®¡ç†è€…ä¸€ä¸ªå°±å¤Ÿï¼‰`ï¼‰
2. Hadoop HDFSçš„å·¥ä½œè§’è‰²ï¼šDatanodeè¿›ç¨‹ï¼ˆ`éœ€è¦å¤šä¸ªï¼ˆå·¥äººï¼Œè¶Šå¤šè¶Šå¥½ï¼Œä¸€ä¸ªæœºå™¨å¯åŠ¨ä¸€ä¸ªï¼‰`ï¼‰
3. Hadoop YARNçš„ç®¡ç†è§’è‰²ï¼šResourceManagerè¿›ç¨‹ï¼ˆ`ä»…éœ€1ä¸ªå³å¯ï¼ˆç®¡ç†è€…ä¸€ä¸ªå°±å¤Ÿï¼‰`ï¼‰
4. Hadoop YARNçš„å·¥ä½œè§’è‰²ï¼šNodeManagerè¿›ç¨‹ï¼ˆ`éœ€è¦å¤šä¸ªï¼ˆå·¥äººï¼Œè¶Šå¤šè¶Šå¥½ï¼Œä¸€ä¸ªæœºå™¨å¯åŠ¨ä¸€ä¸ªï¼‰`ï¼‰
5. Hadoop å†å²è®°å½•æœåŠ¡å™¨è§’è‰²ï¼šHistoryServerè¿›ç¨‹ï¼ˆ`ä»…éœ€1ä¸ªå³å¯ï¼ˆåŠŸèƒ½è¿›ç¨‹æ— éœ€å¤ªå¤š1ä¸ªè¶³å¤Ÿï¼‰`ï¼‰
6. Hadoop ä»£ç†æœåŠ¡å™¨è§’è‰²ï¼šWebProxyServerè¿›ç¨‹ï¼ˆ`ä»…éœ€1ä¸ªå³å¯ï¼ˆåŠŸèƒ½è¿›ç¨‹æ— éœ€å¤ªå¤š1ä¸ªè¶³å¤Ÿï¼‰`ï¼‰
7. Zookeeperçš„è¿›ç¨‹ï¼šQuorumPeerMainè¿›ç¨‹ï¼ˆ`ä»…éœ€1ä¸ªå³å¯ï¼ˆZookeeperçš„å·¥ä½œè€…ï¼Œè¶Šå¤šè¶Šå¥½ï¼‰`ï¼‰

#### 4.1.3 è§’è‰²å’ŒèŠ‚ç‚¹åˆ†é…

è§’è‰²åˆ†é…å¦‚ä¸‹ï¼š
1. node1:Namenodeã€Datanodeã€ResourceManagerã€NodeManagerã€HistoryServerã€WebProxyServerã€QuorumPeerMain
2. node2:Datanodeã€NodeManagerã€QuorumPeerMain
3. node3:Datanodeã€NodeManagerã€QuorumPeerMain

![image-20221026202935745|380](https://my-obsidian-image.oss-cn-guangzhou.aliyuncs.com/2024/04/cd3874192a2a9d13af4f500655c825cf.png)

### 4.2 å®‰è£…

#### 4.2.1 è°ƒæ•´è™šæ‹Ÿæœºå†…å­˜

å¦‚ä¸Šå›¾ï¼Œå¯ä»¥çœ‹å‡ºnode1æ‰¿è½½äº†å¤ªå¤šçš„å‹åŠ›ã€‚åŒæ—¶node2å’Œnode3ä¹ŸåŒæ—¶è¿è¡Œäº†ä¸å°‘ç¨‹åº

ä¸ºäº†ç¡®ä¿é›†ç¾¤çš„ç¨³å®šï¼Œéœ€è¦å¯¹è™šæ‹Ÿæœºè¿›è¡Œå†…å­˜è®¾ç½®ã€‚

è¯·åœ¨VMwareä¸­ï¼Œå¯¹ï¼š

1. node1è®¾ç½®4GBæˆ–ä»¥ä¸Šå†…å­˜
2. node2å’Œnode3è®¾ç½®2GBæˆ–ä»¥ä¸Šå†…å­˜


> å¤§æ•°æ®çš„è½¯ä»¶æœ¬èº«å°±æ˜¯é›†ç¾¤åŒ–ï¼ˆä¸€å †æœåŠ¡å™¨ï¼‰ä¸€èµ·è¿è¡Œçš„ã€‚
>
> ç°åœ¨æˆ‘ä»¬åœ¨ä¸€å°ç”µè„‘ä¸­ä»¥å¤šå°è™šæ‹Ÿæœºæ¥æ¨¡æ‹Ÿé›†ç¾¤ï¼Œç¡®å®ä¼šæœ‰å¾ˆå¤§çš„å†…å­˜å‹åŠ›å“¦ã€‚

#### 4.2.2 Zookeeperé›†ç¾¤éƒ¨ç½²

ç•¥

#### 4.2.3 Hadoopé›†ç¾¤éƒ¨ç½²

1. ä¸‹è½½Hadoopå®‰è£…åŒ…ã€è§£å‹ã€é…ç½®è½¯é“¾æ¥
   ```shell
   # 1. ä¸‹è½½
   wget http://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
   
   # 2. è§£å‹
   # è¯·ç¡®ä¿ç›®å½•/export/serverå­˜åœ¨
   tar -zxvf hadoop-3.3.0.tar.gz -C /export/server/
   
   # 3. æ„å»ºè½¯é“¾æ¥
   ln -s /export/server/hadoop-3.3.0 /export/server/hadoop
   ```

2. ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š`hadoop-env.sh`

   > Hadoopçš„é…ç½®æ–‡ä»¶è¦ä¿®æ”¹çš„åœ°æ–¹å¾ˆå¤šï¼Œè¯·ç»†å¿ƒ

   cd è¿›å…¥åˆ°/export/server/hadoop/etc/hadoopï¼Œæ–‡ä»¶å¤¹ä¸­ï¼Œé…ç½®æ–‡ä»¶éƒ½åœ¨è¿™é‡Œ

   ä¿®æ”¹hadoop-env.shæ–‡ä»¶

   > æ­¤æ–‡ä»¶æ˜¯é…ç½®ä¸€äº›Hadoopç”¨åˆ°çš„ç¯å¢ƒå˜é‡
   >
   > è¿™äº›æ˜¯ä¸´æ—¶å˜é‡ï¼Œåœ¨Hadoopè¿è¡Œæ—¶æœ‰ç”¨
   >
   > å¦‚æœè¦æ°¸ä¹…ç”Ÿæ•ˆï¼Œéœ€è¦å†™åˆ°/etc/profileä¸­
   ```shell
   # åœ¨æ–‡ä»¶å¼€å¤´åŠ å…¥ï¼š
   # é…ç½®Javaå®‰è£…è·¯å¾„
   export JAVA_HOME=/export/server/jdk
   # é…ç½®Hadoopå®‰è£…è·¯å¾„
   export HADOOP_HOME=/export/server/hadoop
   # Hadoop hdfsé…ç½®æ–‡ä»¶è·¯å¾„
   export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
   # Hadoop YARNé…ç½®æ–‡ä»¶è·¯å¾„
   export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
   # Hadoop YARN æ—¥å¿—æ–‡ä»¶å¤¹
   export YARN_LOG_DIR=$HADOOP_HOME/logs/yarn
   # Hadoop hdfs æ—¥å¿—æ–‡ä»¶å¤¹
   export HADOOP_LOG_DIR=$HADOOP_HOME/logs/hdfs
   
   # Hadoopçš„ä½¿ç”¨å¯åŠ¨ç”¨æˆ·é…ç½®
   export HDFS_NAMENODE_USER=root
   export HDFS_DATANODE_USER=root
   export HDFS_SECONDARYNAMENODE_USER=root
   export YARN_RESOURCEMANAGER_USER=root
   export YARN_NODEMANAGER_USER=root
   export YARN_PROXYSERVER_USER=root
   ```

3. ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š`core-site.xml`

   å¦‚ä¸‹ï¼Œæ¸…ç©ºæ–‡ä»¶ï¼Œå¡«å…¥å¦‚ä¸‹å†…å®¹
   ```xml
   <?xml version="1.0" encoding="UTF-8"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   <!--
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
   
       http://www.apache.org/licenses/LICENSE-2.0
   
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License. See accompanying LICENSE file.
   -->
   
   <!-- Put site-specific property overrides in this file. -->
   <configuration>
     <property>
       <name>fs.defaultFS</name>
       <value>hdfs://node1:8020</value>
       <description></description>
     </property>
   
     <property>
       <name>io.file.buffer.size</name>
       <value>131072</value>
       <description></description>
     </property>
   </configuration>
   ```

4. é…ç½®ï¼š`hdfs-site.xml`æ–‡ä»¶
   ```xml
   <?xml version="1.0" encoding="UTF-8"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   <!--
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
   
       http://www.apache.org/licenses/LICENSE-2.0
   
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License. See accompanying LICENSE file.
   -->
   
   <!-- Put site-specific property overrides in this file. -->
   
   <configuration>
       <property>
           <name>dfs.datanode.data.dir.perm</name>
           <value>700</value>
       </property>
   
     <property>
       <name>dfs.namenode.name.dir</name>
       <value>/data/nn</value>
       <description>Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently.</description>
     </property>
   
     <property>
       <name>dfs.namenode.hosts</name>
       <value>node1,node2,node3</value>
       <description>List of permitted DataNodes.</description>
     </property>
   
     <property>
       <name>dfs.blocksize</name>
       <value>268435456</value>
       <description></description>
     </property>
   
   
     <property>
       <name>dfs.namenode.handler.count</name>
       <value>100</value>
       <description></description>
     </property>
   
     <property>
       <name>dfs.datanode.data.dir</name>
       <value>/data/dn</value>
     </property>
   </configuration>
   ```

5. é…ç½®ï¼š`mapred-env.sh`æ–‡ä»¶
   ```shell
   # åœ¨æ–‡ä»¶çš„å¼€å¤´åŠ å…¥å¦‚ä¸‹ç¯å¢ƒå˜é‡è®¾ç½®
   export JAVA_HOME=/export/server/jdk
   export HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1000
   export HADOOP_MAPRED_ROOT_LOGGER=INFO,RFA
   ```

6. é…ç½®ï¼š`mapred-site.xml`æ–‡ä»¶
   ```xml
   <?xml version="1.0"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   <!--
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
   
       http://www.apache.org/licenses/LICENSE-2.0
   
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License. See accompanying LICENSE file.
   -->
   
   <!-- Put site-specific property overrides in this file. -->
   
   <configuration>
     <property>
       <name>mapreduce.framework.name</name>
       <value>yarn</value>
       <description></description>
     </property>
   
     <property>
       <name>mapreduce.jobhistory.address</name>
       <value>node1:10020</value>
       <description></description>
     </property>
   
   
     <property>
       <name>mapreduce.jobhistory.webapp.address</name>
       <value>node1:19888</value>
       <description></description>
     </property>
   
   
     <property>
       <name>mapreduce.jobhistory.intermediate-done-dir</name>
       <value>/data/mr-history/tmp</value>
       <description></description>
     </property>
   
   
     <property>
       <name>mapreduce.jobhistory.done-dir</name>
       <value>/data/mr-history/done</value>
       <description></description>
     </property>
   <property>
     <name>yarn.app.mapreduce.am.env</name>
     <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
   </property>
   <property>
     <name>mapreduce.map.env</name>
     <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
   </property>
   <property>
     <name>mapreduce.reduce.env</name>
     <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
   </property>
   </configuration>
   ```

7. é…ç½®ï¼š`yarn-env.sh`æ–‡ä»¶

   ```shell
   # åœ¨æ–‡ä»¶çš„å¼€å¤´åŠ å…¥å¦‚ä¸‹ç¯å¢ƒå˜é‡è®¾ç½®
   export JAVA_HOME=/export/server/jdk
   export HADOOP_HOME=/export/server/hadoop
   export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
   export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
   export YARN_LOG_DIR=$HADOOP_HOME/logs/yarn
   export HADOOP_LOG_DIR=$HADOOP_HOME/logs/hdfs
   ```

8. é…ç½®ï¼š`yarn-site.xml`æ–‡ä»¶
   ```xml
   <?xml version="1.0"?>
   <!--
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
   
       http://www.apache.org/licenses/LICENSE-2.0
   
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License. See accompanying LICENSE file.
   -->
   <configuration>
   
   <!-- Site specific YARN configuration properties -->
   <property>
       <name>yarn.log.server.url</name>
       <value>http://node1:19888/jobhistory/logs</value>
       <description></description>
   </property>
   
     <property>
       <name>yarn.web-proxy.address</name>
       <value>node1:8089</value>
       <description>proxy server hostname and port</description>
     </property>
   
   
     <property>
       <name>yarn.log-aggregation-enable</name>
       <value>true</value>
       <description>Configuration to enable or disable log aggregation</description>
     </property>
   
     <property>
       <name>yarn.nodemanager.remote-app-log-dir</name>
       <value>/tmp/logs</value>
       <description>Configuration to enable or disable log aggregation</description>
     </property>
   
   
   <!-- Site specific YARN configuration properties -->
     <property>
       <name>yarn.resourcemanager.hostname</name>
       <value>node1</value>
       <description></description>
     </property>
   
     <property>
       <name>yarn.resourcemanager.scheduler.class</name>
       <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
       <description></description>
     </property>
   
     <property>
       <name>yarn.nodemanager.local-dirs</name>
       <value>/data/nm-local</value>
       <description>Comma-separated list of paths on the local filesystem where intermediate data is written.</description>
     </property>
   
   
     <property>
       <name>yarn.nodemanager.log-dirs</name>
       <value>/data/nm-log</value>
       <description>Comma-separated list of paths on the local filesystem where logs are written.</description>
     </property>
   
   
     <property>
       <name>yarn.nodemanager.log.retain-seconds</name>
       <value>10800</value>
       <description>Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.</description>
     </property>
   
   
   
     <property>
       <name>yarn.nodemanager.aux-services</name>
       <value>mapreduce_shuffle</value>
       <description>Shuffle service that needs to be set for Map Reduce applications.</description>
     </property>
   </configuration>
   ```

9. ä¿®æ”¹workersæ–‡ä»¶
   ```shell
   # å…¨éƒ¨å†…å®¹å¦‚ä¸‹
   node1
   node2
   node3
   ```

10. åˆ†å‘hadoopåˆ°å…¶å®ƒæœºå™¨
   ```shell
   # åœ¨node1æ‰§è¡Œ
   cd /export/server
   
   scp -r hadoop-3.3.0 node2:`pwd`/
   scp -r hadoop-3.3.0 node2:`pwd`/
   ```

11. åœ¨node2ã€node3æ‰§è¡Œ
    ```shell
    # åˆ›å»ºè½¯é“¾æ¥
    ln -s /export/server/hadoop-3.3.0 /export/server/hadoop
    ```

12. åˆ›å»ºæ‰€éœ€ç›®å½•

    - åœ¨node1æ‰§è¡Œï¼š
      ```shell
      mkdir -p /data/nn
      mkdir -p /data/dn
      mkdir -p /data/nm-log
      mkdir -p /data/nm-local
      ```

    - åœ¨node2æ‰§è¡Œï¼š
      ```shell
      mkdir -p /data/dn
      mkdir -p /data/nm-log
      mkdir -p /data/nm-local
      ```

    - åœ¨node3æ‰§è¡Œï¼š
      ```shell
      mkdir -p /data/dn
      mkdir -p /data/nm-log
      mkdir -p /data/nm-local
      ```

13. é…ç½®ç¯å¢ƒå˜é‡

    åœ¨node1ã€node2ã€node3ä¿®æ”¹/etc/profile

    ```shell
    export HADOOP_HOME=/export/server/hadoop
    export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    ```

    æ‰§è¡Œ`source /etc/profile`ç”Ÿæ•ˆ

14. æ ¼å¼åŒ–NameNodeï¼Œåœ¨node1æ‰§è¡Œ

    ```shell
    hadoop namenode -format
    ```

    > hadoopè¿™ä¸ªå‘½ä»¤æ¥è‡ªäºï¼š$HADOOP_HOME/binä¸­çš„ç¨‹åº
    >
    > ç”±äºé…ç½®äº†ç¯å¢ƒå˜é‡PATHï¼Œæ‰€ä»¥å¯ä»¥åœ¨ä»»æ„ä½ç½®æ‰§è¡Œhadoopå‘½ä»¤å“¦

15. å¯åŠ¨hadoopçš„hdfsé›†ç¾¤ï¼Œåœ¨node1æ‰§è¡Œå³å¯

    ```shell
    start-dfs.sh
    
    # å¦‚éœ€åœæ­¢å¯ä»¥æ‰§è¡Œ
    stop-dfs.sh
    ```

    > start-dfs.shè¿™ä¸ªå‘½ä»¤æ¥è‡ªäºï¼š$HADOOP_HOME/sbinä¸­çš„ç¨‹åº
    >
    > ç”±äºé…ç½®äº†ç¯å¢ƒå˜é‡PATHï¼Œæ‰€ä»¥å¯ä»¥åœ¨ä»»æ„ä½ç½®æ‰§è¡Œstart-dfs.shå‘½ä»¤å“¦

16. å¯åŠ¨hadoopçš„yarné›†ç¾¤ï¼Œåœ¨node1æ‰§è¡Œå³å¯

    ```shell
    start-yarn.sh
    
    # å¦‚éœ€åœæ­¢å¯ä»¥æ‰§è¡Œ
    stop-yarn.sh
    ```

17. å¯åŠ¨å†å²æœåŠ¡å™¨

    ```shell
    mapred --daemon start historyserver
    
    # å¦‚éœ€åœæ­¢å°†startæ›´æ¢ä¸ºstop
    ```

18. å¯åŠ¨webä»£ç†æœåŠ¡å™¨

    ```shell
    yarn-daemon.sh start proxyserver
    
    # å¦‚éœ€åœæ­¢å°†startæ›´æ¢ä¸ºstop
    ```



##### 4.2.3.1 éªŒè¯Hadoopé›†ç¾¤è¿è¡Œæƒ…å†µ

1. åœ¨node1ã€node2ã€node3ä¸Šé€šè¿‡jpséªŒè¯è¿›ç¨‹æ˜¯å¦éƒ½å¯åŠ¨æˆåŠŸ

2. éªŒè¯HDFSï¼Œæµè§ˆå™¨æ‰“å¼€ï¼šhttp://node1:9870

   åˆ›å»ºæ–‡ä»¶test.txtï¼Œéšæ„å¡«å…¥å†…å®¹ï¼Œå¹¶æ‰§è¡Œï¼š

   ```shell
   hadoop fs -put test.txt /test.txt
   
   hadoop fs -cat /test.txt
   ```

3. éªŒè¯YARNï¼Œæµè§ˆå™¨æ‰“å¼€ï¼šhttp://node1:8088

   æ‰§è¡Œï¼š

   ```shell
   # åˆ›å»ºæ–‡ä»¶words.txtï¼Œå¡«å…¥å¦‚ä¸‹å†…å®¹
   itheima itcast hadoop
   itheima hadoop hadoop
   itheima itcast
   
   # å°†æ–‡ä»¶ä¸Šä¼ åˆ°HDFSä¸­
   hadoop fs -put words.txt /words.txt
   
   # æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤éªŒè¯YARNæ˜¯å¦æ­£å¸¸
   hadoop jar /export/server/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar wordcount -Dmapred.job.queue.name=root.root /words.txt /output
   ```



## 5 å¤§æ•°æ®NoSQLæ•°æ®åº“HBaseé›†ç¾¤éƒ¨ç½²

### 5.1 ç®€ä»‹

HBase æ˜¯ä¸€ç§[åˆ†å¸ƒå¼](https://so.csdn.net/so/search?q=åˆ†å¸ƒå¼&spm=1001.2101.3001.7020)ã€å¯æ‰©å±•ã€æ”¯æŒæµ·é‡æ•°æ®å­˜å‚¨çš„ NoSQL æ•°æ®åº“ã€‚



å’ŒRedisä¸€æ ·ï¼ŒHBaseæ˜¯ä¸€æ¬¾KeyValueå‹å­˜å‚¨çš„æ•°æ®åº“ã€‚

ä¸è¿‡å’ŒRedisè®¾è®¡æ–¹å‘ä¸åŒ

- Redisè®¾è®¡ä¸ºå°‘é‡æ•°æ®ï¼Œè¶…å¿«æ£€ç´¢
- HBaseè®¾è®¡ä¸ºæµ·é‡æ•°æ®ï¼Œå¿«é€Ÿæ£€ç´¢

HBaseåœ¨å¤§æ•°æ®é¢†åŸŸåº”ç”¨ååˆ†å¹¿æ³›ï¼Œç°åœ¨æˆ‘ä»¬æ¥åœ¨node1ã€node2ã€node3ä¸Šéƒ¨ç½²HBaseé›†ç¾¤ã€‚

### 5.2 å®‰è£…

1. HBaseä¾èµ–Zookeeperã€JDKã€Hadoopï¼ˆHDFSï¼‰ï¼Œè¯·ç¡®ä¿å·²ç»å®Œæˆå‰é¢

   - é›†ç¾¤åŒ–è½¯ä»¶å‰ç½®å‡†å¤‡ï¼ˆJDKï¼‰
   - Zookeeper
   - Hadoop
   - è¿™äº›ç¯èŠ‚çš„è½¯ä»¶å®‰è£…

2. ã€node1æ‰§è¡Œã€‘ä¸‹è½½HBaseå®‰è£…åŒ…

   ```shell
   # ä¸‹è½½
   wget http://archive.apache.org/dist/hbase/2.1.0/hbase-2.1.0-bin.tar.gz
   
   # è§£å‹
   tar -zxvf hbase-2.1.0-bin.tar.gz -C /export/server
   
   # é…ç½®è½¯é“¾æ¥
   ln -s /export/server/hbase-2.1.0 /export/server/hbase
   ```

3. ã€node1æ‰§è¡Œã€‘ï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹`conf/hbase-env.sh`æ–‡ä»¶

   ```shell
   # åœ¨28è¡Œé…ç½®JAVA_HOME
   export JAVA_HOME=/export/server/jdk
   # åœ¨126è¡Œé…ç½®ï¼š
   # æ„æ€è¡¨ç¤ºï¼Œä¸ä½¿ç”¨HBaseè‡ªå¸¦çš„Zookeeperï¼Œè€Œæ˜¯ç”¨ç‹¬ç«‹Zookeeper
   export HBASE_MANAGES_ZK=false
   # åœ¨ä»»æ„è¡Œï¼Œæ¯”å¦‚26è¡Œï¼Œæ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š
   export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP="true"
   ```

4. ã€node1æ‰§è¡Œã€‘ï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹`conf/hbase-site.xml`æ–‡ä»¶

   ```shell
   # å°†æ–‡ä»¶çš„å…¨éƒ¨å†…å®¹æ›¿æ¢æˆå¦‚ä¸‹å†…å®¹ï¼š
   <configuration>
           <!-- HBaseæ•°æ®åœ¨HDFSä¸­çš„å­˜æ”¾çš„è·¯å¾„ -->
           <property>
               <name>hbase.rootdir</name>
               <value>hdfs://node1:8020/hbase</value>
           </property>
           <!-- Hbaseçš„è¿è¡Œæ¨¡å¼ã€‚falseæ˜¯å•æœºæ¨¡å¼ï¼Œtrueæ˜¯åˆ†å¸ƒå¼æ¨¡å¼ã€‚è‹¥ä¸ºfalse,Hbaseå’ŒZookeeperä¼šè¿è¡Œåœ¨åŒä¸€ä¸ªJVMé‡Œé¢ -->
           <property>
               <name>hbase.cluster.distributed</name>
               <value>true</value>
           </property>
           <!-- ZooKeeperçš„åœ°å€ -->
           <property>
               <name>hbase.zookeeper.quorum</name>
               <value>node1,node2,node3</value>
           </property>
           <!-- ZooKeeperå¿«ç…§çš„å­˜å‚¨ä½ç½® -->
           <property>
               <name>hbase.zookeeper.property.dataDir</name>
               <value>/export/server/apache-zookeeper-3.6.0-bin/data</value>
           </property>
           <!--  V2.1ç‰ˆæœ¬ï¼Œåœ¨åˆ†å¸ƒå¼æƒ…å†µä¸‹, è®¾ç½®ä¸ºfalse -->
           <property>
               <name>hbase.unsafe.stream.capability.enforce</name>
               <value>false</value>
           </property>
   </configuration>
   ```

5. ã€node1æ‰§è¡Œã€‘ï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹`conf/regionservers`æ–‡ä»¶

   ```shell
   # å¡«å…¥å¦‚ä¸‹å†…å®¹
   node1
   node2
   node3
   ```

6. ã€node1æ‰§è¡Œã€‘ï¼Œåˆ†å‘hbaseåˆ°å…¶å®ƒæœºå™¨

   ```shell
   scp -r /export/server/hbase-2.1.0 node2:/export/server/
   scp -r /export/server/hbase-2.1.0 node3:/export/server/
   ```

7. ã€node2ã€node3æ‰§è¡Œã€‘ï¼Œé…ç½®è½¯é“¾æ¥

   ```shell
   ln -s /export/server/hbase-2.1.0 /export/server/hbase
   ```

8. ã€node1ã€node2ã€node3æ‰§è¡Œã€‘ï¼Œé…ç½®ç¯å¢ƒå˜é‡

   ```shell
   # é…ç½®åœ¨/etc/profileå†…ï¼Œè¿½åŠ å¦‚ä¸‹ä¸¤è¡Œ
   export HBASE_HOME=/export/server/hbase
   export PATH=$HBASE_HOME/bin:$PATH
   
   source /etc/profile
   ```

9. ã€node1æ‰§è¡Œã€‘å¯åŠ¨HBase

   > è¯·ç¡®ä¿ï¼šHadoop HDFSã€Zookeeperæ˜¯å·²ç»å¯åŠ¨äº†çš„

   ```shell
   start-hbase.sh
   
   # å¦‚éœ€åœæ­¢å¯ä½¿ç”¨
   stop-hbase.sh
   ```

   > ç”±äºæˆ‘ä»¬é…ç½®äº†ç¯å¢ƒå˜é‡export PATH=$PATH:$HBASE_HOME/bin
   >
   > start-hbase.shå³åœ¨$HBASE_HOME/binå†…ï¼Œæ‰€ä»¥å¯ä»¥æ— è®ºå½“å‰ç›®å½•åœ¨å“ªï¼Œå‡å¯ç›´æ¥æ‰§è¡Œ

10. éªŒè¯HBase

    æµè§ˆå™¨æ‰“å¼€ï¼šhttp://node1:16010ï¼Œå³å¯çœ‹åˆ°HBaseçš„WEB UIé¡µé¢

11. ç®€å•æµ‹è¯•ä½¿ç”¨HBase

    ã€node1æ‰§è¡Œã€‘

    ```shell
    hbase shell
    
    # åˆ›å»ºè¡¨
    create 'test', 'cf'
    
    # æ’å…¥æ•°æ®
    put 'test', 'rk001', 'cf:info', 'itheima'
    
    # æŸ¥è¯¢æ•°æ®
    get 'test', 'rk001'
    
    # æ‰«æè¡¨æ•°æ®
    scan 'test'
    ```


## 6 åˆ†å¸ƒå¼å†…å­˜è®¡ç®—Sparkç¯å¢ƒéƒ¨ç½²

### 6.1 æ³¨æ„

æœ¬å°èŠ‚çš„æ“ä½œï¼ŒåŸºäºï¼š`å¤§æ•°æ®é›†ç¾¤ï¼ˆHadoopç”Ÿæ€ï¼‰å®‰è£…éƒ¨ç½²`ç¯èŠ‚ä¸­æ‰€æ„å»ºçš„Hadoopé›†ç¾¤

å¦‚æœæ²¡æœ‰Hadoopé›†ç¾¤ï¼Œè¯·å‚é˜…å‰ç½®å†…å®¹ï¼Œéƒ¨ç½²å¥½ç¯å¢ƒã€‚

### 6.2 ç®€ä»‹

Sparkæ˜¯ä¸€æ¬¾åˆ†å¸ƒå¼å†…å­˜è®¡ç®—å¼•æ“ï¼Œå¯ä»¥æ”¯æ’‘æµ·é‡æ•°æ®çš„åˆ†å¸ƒå¼è®¡ç®—ã€‚

Sparkåœ¨å¤§æ•°æ®ä½“ç³»æ˜¯æ˜æ˜Ÿäº§å“ï¼Œä½œä¸ºæœ€æ–°ä¸€ä»£çš„ç»¼åˆè®¡ç®—å¼•æ“ï¼Œæ”¯æŒç¦»çº¿è®¡ç®—å’Œå®æ—¶è®¡ç®—ã€‚

åœ¨å¤§æ•°æ®é¢†åŸŸå¹¿æ³›åº”ç”¨ï¼Œæ˜¯ç›®å‰ä¸–ç•Œä¸Šä½¿ç”¨æœ€å¤šçš„å¤§æ•°æ®åˆ†å¸ƒå¼è®¡ç®—å¼•æ“ã€‚

æˆ‘ä»¬å°†åŸºäºå‰é¢æ„å»ºçš„Hadoopé›†ç¾¤ï¼Œéƒ¨ç½²Spark Standaloneé›†ç¾¤ã€‚

### 6.3 å®‰è£…

1. ã€node1æ‰§è¡Œã€‘ä¸‹è½½å¹¶è§£å‹

   ```shell
   wget https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz
   
   # è§£å‹
   tar -zxvf spark-2.4.5-bin-hadoop2.7.tgz -C /export/server/
   
   # è½¯é“¾æ¥
   ln -s /export/server/spark-2.4.5-bin-hadoop2.7 /export/server/spark
   ```

2. ã€node1æ‰§è¡Œã€‘ä¿®æ”¹é…ç½®æ–‡ä»¶åç§°
   ```shell
   # æ”¹å
   cd /export/server/spark/conf
   mv spark-env.sh.template spark-env.sh
   mv slaves.template slaves
   ```

3. ã€node1æ‰§è¡Œã€‘ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œ`spark-env.sh`
   ```shell
   ## è®¾ç½®JAVAå®‰è£…ç›®å½•
   JAVA_HOME=/export/server/jdk
   
   ## HADOOPè½¯ä»¶é…ç½®æ–‡ä»¶ç›®å½•ï¼Œè¯»å–HDFSä¸Šæ–‡ä»¶å’Œè¿è¡ŒYARNé›†ç¾¤
   HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop
   YARN_CONF_DIR=/export/server/hadoop/etc/hadoop
   
   ## æŒ‡å®šsparkè€å¤§Masterçš„IPå’Œæäº¤ä»»åŠ¡çš„é€šä¿¡ç«¯å£
   export SPARK_MASTER_HOST=node1
   export SPARK_MASTER_PORT=7077
   
   SPARK_MASTER_WEBUI_PORT=8080
   SPARK_WORKER_CORES=1
   SPARK_WORKER_MEMORY=1g
   ```

4. ã€node1æ‰§è¡Œã€‘ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œ`slaves`
   ```shell
   node1
   node2
   node3
   ```

5. ã€node1æ‰§è¡Œã€‘åˆ†å‘
   ```shell
   scp -r spark-2.4.5-bin-hadoop2.7 node2:$PWD
   scp -r spark-2.4.5-bin-hadoop2.7 node3:$PWD
   ```

6. ã€node2ã€node3æ‰§è¡Œã€‘è®¾ç½®è½¯é“¾æ¥
   ```shell
   ln -s /export/server/spark-2.4.5-bin-hadoop2.7 /export/server/spark
   ```

7. ã€node1æ‰§è¡Œã€‘å¯åŠ¨Sparké›†ç¾¤
   ```shell
   /export/server/spark/sbin/start-all.sh
   
   # å¦‚éœ€åœæ­¢ï¼Œå¯ä»¥
   /export/server/spark/sbin/stop-all.sh
   ```

8. æ‰“å¼€Sparkç›‘æ§é¡µé¢ï¼Œæµè§ˆå™¨æ‰“å¼€ï¼šhttp://node1:8081

9. ã€node1æ‰§è¡Œã€‘æäº¤æµ‹è¯•ä»»åŠ¡
   ```shell
   /export/server/spark/bin/spark-submit --master spark://node1:7077 --class org.apache.spark.examples.SparkPi /export/server/spark/examples/jars/spark-examples_2.11-2.4.5.jar
   ```

## 7 åˆ†å¸ƒå¼å†…å­˜è®¡ç®—Flinkç¯å¢ƒéƒ¨ç½²

### 7.1 æ³¨æ„

æœ¬å°èŠ‚çš„æ“ä½œï¼ŒåŸºäºï¼š`å¤§æ•°æ®é›†ç¾¤ï¼ˆHadoopç”Ÿæ€ï¼‰å®‰è£…éƒ¨ç½²`ç¯èŠ‚ä¸­æ‰€æ„å»ºçš„Hadoopé›†ç¾¤

å¦‚æœæ²¡æœ‰Hadoopé›†ç¾¤ï¼Œè¯·å‚é˜…å‰ç½®å†…å®¹ï¼Œéƒ¨ç½²å¥½ç¯å¢ƒã€‚
### 7.2 ç®€ä»‹

FlinkåŒSparkä¸€æ ·ï¼Œæ˜¯ä¸€æ¬¾åˆ†å¸ƒå¼å†…å­˜è®¡ç®—å¼•æ“ï¼Œå¯ä»¥æ”¯æ’‘æµ·é‡æ•°æ®çš„åˆ†å¸ƒå¼è®¡ç®—ã€‚

Flinkåœ¨å¤§æ•°æ®ä½“ç³»åŒæ ·æ˜¯æ˜æ˜Ÿäº§å“ï¼Œä½œä¸ºæœ€æ–°ä¸€ä»£çš„ç»¼åˆè®¡ç®—å¼•æ“ï¼Œæ”¯æŒç¦»çº¿è®¡ç®—å’Œå®æ—¶è®¡ç®—ã€‚

åœ¨å¤§æ•°æ®é¢†åŸŸå¹¿æ³›åº”ç”¨ï¼Œæ˜¯ç›®å‰ä¸–ç•Œä¸Šé™¤å»Sparkä»¥å¤–ï¼Œåº”ç”¨æœ€ä¸ºå¹¿æ³›çš„åˆ†å¸ƒå¼è®¡ç®—å¼•æ“ã€‚

æˆ‘ä»¬å°†åŸºäºå‰é¢æ„å»ºçš„Hadoopé›†ç¾¤ï¼Œéƒ¨ç½²Flink Standaloneé›†ç¾¤

Sparkæ›´åŠ åå‘äºç¦»çº¿è®¡ç®—è€ŒFlinkæ›´åŠ åå‘äºå®æ—¶è®¡ç®—ã€‚

### 7.3 å®‰è£…

1. ã€node1æ“ä½œã€‘ä¸‹è½½å®‰è£…åŒ…
   ```shell
   wget https://archive.apache.org/dist/flink/flink-1.10.0/flink-1.10.0-bin-scala_2.11.tgz
   
   # è§£å‹
   tar -zxvf flink-1.10.0-bin-scala_2.11.tgz -C /export/server/
   
   # è½¯é“¾æ¥
   ln -s /export/server/flink-1.10.0 /export/server/flink
   ```

2. ã€node1æ“ä½œã€‘ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œ`conf/flink-conf.yaml`
   ```yaml
   # jobManager çš„IPåœ°å€
   jobmanager.rpc.address: node1
   # JobManager çš„ç«¯å£å·
   jobmanager.rpc.port: 6123
   # JobManager JVM heap å†…å­˜å¤§å°
   jobmanager.heap.size: 1024m
   # TaskManager JVM heap å†…å­˜å¤§å°
   taskmanager.heap.size: 1024m
   # æ¯ä¸ª TaskManager æä¾›çš„ä»»åŠ¡ slots æ•°é‡å¤§å°
   taskmanager.numberOfTaskSlots: 2
   #æ˜¯å¦è¿›è¡Œé¢„åˆ†é…å†…å­˜ï¼Œé»˜è®¤ä¸è¿›è¡Œé¢„åˆ†é…ï¼Œè¿™æ ·åœ¨æˆ‘ä»¬ä¸ä½¿ç”¨flinké›†ç¾¤æ—¶å€™ä¸ä¼šå ç”¨é›†ç¾¤èµ„æº
   taskmanager.memory.preallocate: false
   # ç¨‹åºé»˜è®¤å¹¶è¡Œè®¡ç®—çš„ä¸ªæ•°
   parallelism.default: 1
   #JobManagerçš„Webç•Œé¢çš„ç«¯å£ï¼ˆé»˜è®¤ï¼š8081ï¼‰
   jobmanager.web.port: 8081
   ```

3. ã€node1æ“ä½œã€‘ï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œ`conf/slaves`
   ```shell
   node1
   node2
   node3
   ```

4. ã€node1æ“ä½œã€‘åˆ†å‘Flinkå®‰è£…åŒ…åˆ°å…¶å®ƒæœºå™¨
   ```shell
   cd /export/server
   scp -r flink-1.10.0 node2:`pwd`/
   scp -r flink-1.10.0 node3:`pwd`/
   ```

5. ã€node2ã€node3æ“ä½œã€‘
   ```shell
   # é…ç½®è½¯é“¾æ¥
   ln -s /export/server/flink-1.10.0 /export/server/flink
   ```

6. ã€node1æ“ä½œã€‘ï¼Œå¯åŠ¨Flink
   ```shell
   /export/server/flink/bin/start-cluster.sh
   ```

7. éªŒè¯Flinkå¯åŠ¨
   ```shell
   # æµè§ˆå™¨æ‰“å¼€
   http://node1:8081
   ```

8. æäº¤æµ‹è¯•ä»»åŠ¡
   ã€node1æ‰§è¡Œã€‘
   ```shell
   /export/server/flink/bin/flink run /export/server/flink-1.10.0/examples/batch/WordCount.jar
   ```

## 8 è¿ç»´ç›‘æ§Zabbixéƒ¨ç½²

### 8.1 ç®€ä»‹

Zabbix ç”± Alexei Vladishev åˆ›å»ºï¼Œç›®å‰ç”±å…¶æˆç«‹çš„å…¬å¸â€”â€” Zabbix SIA ç§¯æçš„æŒç»­å¼€å‘æ›´æ–°ç»´æŠ¤ï¼Œ å¹¶ä¸ºç”¨æˆ·æä¾›æŠ€æœ¯æ”¯æŒæœåŠ¡ã€‚

Zabbix æ˜¯ä¸€ä¸ª==ä¼ä¸šçº§åˆ†å¸ƒå¼å¼€æºç›‘æ§è§£å†³æ–¹æ¡ˆ==ã€‚

Zabbix è½¯ä»¶èƒ½å¤Ÿ==ç›‘æ§==ä¼—å¤šç½‘ç»œå‚æ•°å’ŒæœåŠ¡å™¨çš„==å¥åº·åº¦ã€å®Œæ•´æ€§==ã€‚Zabbix ä½¿ç”¨çµæ´»çš„å‘Šè­¦æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·ä¸ºå‡ ä¹ä»»ä½•äº‹ä»¶é…ç½®åŸºäºé‚®ä»¶çš„å‘Šè­¦ã€‚è¿™æ ·ç”¨æˆ·å¯ä»¥å¿«é€Ÿå“åº”æœåŠ¡å™¨é—®é¢˜ã€‚Zabbix åŸºäºå­˜å‚¨çš„æ•°æ®æä¾›å‡ºè‰²çš„æŠ¥è¡¨å’Œæ•°æ®å¯è§†åŒ–åŠŸèƒ½ã€‚è¿™äº›åŠŸèƒ½ä½¿å¾— Zabbix æˆä¸ºå®¹é‡è§„åˆ’çš„ç†æƒ³é€‰æ‹©ã€‚

### 8.2 å®‰è£…

>  å®‰è£…æ•´ä½“æ­¥éª¤:

1. å‡†å¤‡Linux æœåŠ¡å™¨(è™šæ‹Ÿæœº)
2. å®‰è£…Mysql
3. å®‰è£…zabbix( åŒ…å« server  agent  web)
4. é…ç½® mysql, ä¸ºzabbixåˆ›å»ºè¡¨ç»“æ„
5. é…ç½®zabbix server
6. å¯åŠ¨å¹¶å¼€å¯å¼€æœºè‡ªå¯åŠ¨

![[Pasted image 20230909174137.png]]

#### 8.2.1 å®‰è£…å‰å‡†å¤‡ - MySql

å®‰è£…ZabbixServeréœ€è¦å…ˆå®‰è£…å¥½`Mysql`æ•°æ®åº“

è¯¾ç¨‹ä½¿ç”¨`Mysql 5.7`

å®‰è£…æ­¥éª¤ï¼š
```shell
# å®‰è£…Mysql yumåº“
rpm -Uvh http://repo.mysql.com//mysql57-community-release-el7-7.noarch.rpm

# yumå®‰è£…Mysql
yum -y install mysql-community-server

# å¯åŠ¨Mysqlè®¾ç½®å¼€æœºå¯åŠ¨
systemctl start mysqld
systemctl enable mysqld

# æ£€æŸ¥MysqlæœåŠ¡çŠ¶æ€
systemctl status mysqld

# ç¬¬ä¸€æ¬¡å¯åŠ¨mysqlï¼Œä¼šåœ¨æ—¥å¿—æ–‡ä»¶ä¸­ç”Ÿæˆrootç”¨æˆ·çš„ä¸€ä¸ªéšæœºå¯†ç ï¼Œä½¿ç”¨ä¸‹é¢å‘½ä»¤æŸ¥çœ‹è¯¥å¯†ç 
grep 'temporary password' /var/log/mysqld.log

# ä¿®æ”¹rootç”¨æˆ·å¯†ç 
mysql -u root -p -h localhost
Enter password:
 
mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'Root!@#$';

# å¦‚æœä½ æƒ³è®¾ç½®ç®€å•å¯†ç ï¼Œéœ€è¦é™ä½Mysqlçš„å¯†ç å®‰å…¨çº§åˆ«
set global validate_password_policy=LOW; # å¯†ç å®‰å…¨çº§åˆ«ä½
set global validate_password_length=4;	 # å¯†ç é•¿åº¦æœ€ä½4ä½å³å¯

# ç„¶åå°±å¯ä»¥ç”¨ç®€å•å¯†ç äº†ï¼ˆè¯¾ç¨‹ä¸­ä½¿ç”¨ç®€å•å¯†ç ï¼Œä¸ºäº†æ–¹ä¾¿ï¼Œç”Ÿäº§ä¸­ä¸è¦è¿™æ ·ï¼‰
ALTER USER 'root'@'localhost' IDENTIFIED BY 'root';
mysql> grant all privileges on *.* to root@'%' identified by 'root';
```

#### 8.2.2 å®‰è£…Zabbix Server å’Œ Zabbix Agent

> åˆå§‹å®‰è£…ï¼Œæˆ‘ä»¬å…ˆå®‰è£…ZabbixServerä»¥åŠåœ¨Serveræœ¬æœºå®‰è£…Agentã€‚

æ‰“å¼€å®˜ç½‘ä¸‹è½½é¡µé¢ï¼š[https://www.zabbix.com/download?zabbix=4.0&os_distribution=centos&os_version=7&db=mysql](https://www.zabbix.com/download?zabbix=4.0&os_distribution=centos&os_version=7&db=mysql)

![[Pasted image 20230909174244.png]]

é€‰æ‹©å¯¹åº”çš„ç‰ˆæœ¬ï¼Œç„¶åå†ä¸‹é¢å®˜ç½‘ç»™å‡ºäº†å…·ä½“çš„å®‰è£…å‘½ä»¤ï¼Œä½¿ç”¨`rpm`å’Œ`yum`æ¥è¿›è¡Œå®‰è£…ã€‚

éœ€è¦æœ‰ç½‘ç»œã€‚

##### 8.2.2.1 å®‰è£…Zabbix yumåº“

[documentation](https://www.zabbix.com/documentation/4.0/manual/installation/install_from_packages)

```shell
rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm
yum clean all
```

##### 8.2.2.2 å®‰è£…Zabbix Serverã€å‰ç«¯ã€Agent

```shell
yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent  
# å¦‚æœåªéœ€è¦å®‰è£…Agentçš„è¯  
yum -y install zabbix-agent
```

##### 8.2.2.3 åˆå§‹åŒ–Mysqlæ•°æ®åº“

[documentation](https://www.zabbix.com/documentation/4.0/manual/appendix/install/db_scripts)

> åœ¨Mysqlä¸­æ“ä½œ

```shell
# ç™»å½•Mysql æ•°æ®åº“  
mysql -uroot -pYourPassword  
mysql> create database zabbix character set utf8 collate utf8_bin;  
mysql> grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';  
# æˆ–è€…: grant all privileges on zabbix.* to zabbix@'%' identified by 'zabbix';  
mysql> quit;
```

æµ‹è¯•åœ¨Zabbix ServeræœåŠ¡å™¨ä¸Šèƒ½å¦è¿œç¨‹ç™»å½•Mysqlï¼Œå¦‚æœå¯ä»¥ç™»å½•ç»§ç»­å‘ä¸‹èµ°ã€‚

Import initial schema and data. You will be prompted to enter your newly created password.

```shell
# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix
```

##### 8.2.2.4 d. ä¸ºZabbix Serveré…ç½®æ•°æ®åº“

Edit file /etc/zabbix/zabbix_server.conf

```shell
DBPassword=password  
DBHost=mysql-host-ip-or-hostname
```

##### 8.2.2.5 e. é…ç½®Zabbixçš„PHPå‰ç«¯

Edit file `/etc/httpd/conf.d/zabbix.conf`, uncomment and set the right timezone for you.`# php_value date.timezone Asia/Shanghai`

Start Zabbix server and agent processes and make it start at system boot:

```shell
systemctl restart zabbix-server zabbix-agent httpd # å¯åŠ¨ã€é‡å¯  
systemctl enable zabbix-server zabbix-agent httpd Â # å¼€æœºè‡ªå¯
```

Now your Zabbix server is up and running!

#### 8.2.3 é…ç½®zabbix å‰ç«¯ï¼ˆWEB UIï¼‰

**æ‰“å¼€:`http://192.168.88.131/zabbix`**

å³å¯è¿›å…¥Zabbixé¡µé¢ï¼Œåœ¨é¦–æ¬¡æ‰“å¼€çš„æ—¶å€™ï¼Œä¼šè¿›å…¥è®¾ç½®é¡µé¢ï¼Œå¦‚å›¾ï¼š![[Pasted image 20230909174603.png]]
**ç‚¹å‡»ä¸‹ä¸€æ­¥ï¼Œä¼šæ£€æŸ¥ç›¸åº”çš„è®¾ç½®æ˜¯å¦éƒ½æ­£å¸¸**![[Pasted image 20230909174614.png]]
å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œç‚¹å‡»ä¸‹ä¸€æ­¥ã€‚

**é…ç½®DBè¿æ¥**![[Pasted image 20230909174626.png]]
æŒ‰å…·ä½“æƒ…å†µå¡«å†™å³å¯

**é…ç½®Serverç»†èŠ‚**![[Pasted image 20230909174638.png]]
å…·ä½“é…ç½®å³å¯ï¼ŒNameè¡¨ç¤ºè¿™ä¸ªZabbixæœåŠ¡çš„åå­—ï¼Œè¿™é‡Œèµ·åå«`ITHEIMA-TEST`

**å®‰è£…å‰æ€»ç»“é¢„è§ˆ**

æ£€æŸ¥ç¡®è®¤æ²¡æœ‰é—®é¢˜å°±ä¸‹ä¸€æ­¥![[Pasted image 20230909174650.png]]
**é…ç½®å®Œæˆ**![[Pasted image 20230909174702.png]]
**åˆå§‹ç®¡ç†å‘˜è´¦æˆ·Adminå¯†ç zabbix**

è¾“å…¥è´¦æˆ·å¯†ç åï¼Œå°±èƒ½è¿›å…¥zabbixé¡µé¢äº†ã€‚

å¦‚ä¸‹å›¾ï¼š![[Pasted image 20230909174716.png]]
ç°åœ¨æ˜¯ä¸€ä¸ªå´­æ–°çš„zabbixç­‰å¾…æˆ‘ä»¬å»æ¢ç´¢ã€‚

## 9 è¿ç»´ç›‘æ§Grafanaéƒ¨ç½²

### 9.1 ç®€ä»‹

### 9.2 å®‰è£…

#### 9.2.1 éƒ¨ç½²å½¢å¼

`Grafana`æ”¯æŒä¸¤ç§éƒ¨ç½²å½¢å¼

1. è‡ªè¡Œéƒ¨ç½², å¯ä»¥éƒ¨ç½²åœ¨æ“ä½œç³»ç»Ÿä¹‹ä¸Š. è‡ªè¡Œæä¾›æœåŠ¡å™¨, åŸŸåç­‰.
   
2. `Grafana`å®˜æ–¹æ‰˜ç®¡. æ— éœ€å®‰è£…, åœ¨çº¿æ³¨å†Œå³å¯å¾—åˆ°ä¸€ä¸ªä¸“å±äºè‡ªå·±çš„`Grafana`, ä½†æ˜¯è¦èŠ±é’±çš„. æ˜¯ä¸€ç§`SaaS`æœåŠ¡
   

æˆ‘ä»¬è¯¾ç¨‹é€‰æ‹©æ–¹å¼1

#### 9.2.2 å®‰è£…

`Grafana`æ”¯æŒå¸¸è§çš„ç»å¤§å¤šæ•°æ“ä½œç³»ç»Ÿ, å¦‚`windows` `mac` `linux` åŒæ—¶ä¹Ÿæ”¯æŒéƒ¨ç½²åœ¨`docker`ä¸­.

å¤§å¤šæ•°æƒ…å†µä¸‹, `Grafana`éƒ½æ˜¯éƒ¨ç½²åœ¨`linux`æœåŠ¡å™¨ä¹‹ä¸Š. æ‰€ä»¥æœ¬è¯¾ç¨‹ä¹Ÿæ˜¯åŸºäº`Linux`ç³»ç»Ÿæ¥è®²è§£.

å¯¹`windows` `mac`ç³»ç»Ÿ æˆ– `docker`éƒ¨ç½²æœ‰å…´è¶£çš„åŒå­¦, è¯·å‚è€ƒ: [https://grafana.com/grafana/download](https://grafana.com/grafana/download)

æˆ‘ä»¬éƒ¨ç½²`Grafana`å¯ä»¥ä½¿ç”¨`YUM`æ¥è¿›è¡Œéƒ¨ç½².

```shell
# åˆ›å»ºä¸€ä¸ªæ–‡ä»¶  
vim /etc/yum.repos.d/grafana.repo  
â€‹  
# å°†ä¸‹é¢çš„å†…å®¹å¤åˆ¶è¿›å»  
[grafana]  
name=grafana  
baseurl=https://packages.grafana.com/oss/rpm  
repo_gpgcheck=1  
enabled=1  
gpgcheck=1  
gpgkey=https://packages.grafana.com/gpg.key  
sslverify=1  
sslcacert=/etc/pki/tls/certs/ca-bundle.crt  
â€‹  
# æœ€åå®‰è£…  
yum install grafana
```

#### 9.2.3 é…ç½®è¯´æ˜

`grafana-server`å…·æœ‰è®¸å¤šé…ç½®é€‰é¡¹ï¼Œè¿™äº›é€‰é¡¹å¯ä»¥åœ¨`.ini`é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šã€‚

> **Note.** `Grafana` needs to be restarted for any configuration changes to take effect.

##### 9.2.3.1 é…ç½®æ–‡ä»¶æ³¨é‡Š

`;`ç¬¦å·åœ¨`.ini`æ–‡ä»¶ä¸­å…¨å±€è¡¨ç¤ºæ³¨é‡Š ()

##### 9.2.3.2 é…ç½®æ–‡ä»¶è·¯å¾„

å¦‚æœæ˜¯è‡ªå·±è§£å‹å®‰è£…, æˆ–è€…è‡ªè¡Œç¼–è¯‘çš„æ–¹å¼å®‰è£…, é…ç½®æ–‡ä»¶åœ¨:

- é»˜è®¤: `$WORKING_DIR/conf/defaults.ini`
  
- è‡ªå®šä¹‰:`$WORKING_DIR/conf/custom.ini`
  
- è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„å¯ä»¥è¢«å‚æ•°`--config`è¦†ç›–
  

> å¯¹äº`YUM` `RPM` å®‰è£…çš„æ–¹å¼, é…ç½®æ–‡ä»¶åœ¨: `/etc/grafana/grafana.ini`

##### 9.2.3.3 ä½¿ç”¨ç¯å¢ƒå˜é‡

å¯ä»¥ä½¿ç”¨ä»¥ä¸‹è¯­æ³•ä½¿ç”¨ç¯å¢ƒå˜é‡æ¥è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„æ‰€æœ‰é€‰é¡¹ï¼š

```bash
GF_<SectionName>_<KeyName>
```

å…¶ä¸­`SectionName`æ˜¯æ–¹æ‹¬å·å†…çš„æ–‡æœ¬ã€‚ä¸€åˆ‡éƒ½åº”ä¸ºå¤§å†™ï¼Œ`.`åº”æ›¿æ¢ä¸º`_` ä¾‹å¦‚ï¼Œç»™å®šä»¥ä¸‹é…ç½®è®¾ç½®ï¼š

```shell
# default section
instance_name = ${HOSTNAME}

[security]
admin_user = admin

[auth.google]
client_secret = 0ldS3cretKey
```

Then you can override them using:

```shell
export GF_DEFAULT_INSTANCE_NAME=my-instance
export GF_SECURITY_ADMIN_USER=true	# GF_ å›ºå®š SECURITY æ˜¯SectionName ADMIN_USER æ˜¯é…ç½®çš„key è½¬å¤§å†™ . è½¬ _
export GF_AUTH_GOOGLE_CLIENT_SECRET=newS3cretKey
```

#### 9.2.4 å¼€å§‹é…ç½®

`Grafana`æ”¯æŒä½¿ç”¨`Sqlite3` `Postgresql` `Mysql`è¿™ä¸‰ç§æ•°æ®åº“ä½œä¸ºå…¶`å…ƒæ•°æ®`çš„å­˜å‚¨.

æˆ‘ä»¬è¯¾ç¨‹ä½¿ç”¨`Mysql`. å’Œ`zabbix`çš„å…ƒæ•°æ®mysqlå…±ç”¨ä¸€ä¸ªå®ä¾‹

åªéœ€è¦é…ç½®å¦‚ä¸‹å†…å®¹å³å¯:![[Pasted image 20230909175045.png]]
å¹¶ç™»é™†mysql, æ‰§è¡Œ:

`create database grafana CHARACTER SET utf8 COLLATE utf8_general_ci;`

åˆ›å»º`Grafana`ä½¿ç”¨çš„æ•°æ®åº“ä½œä¸ºå…ƒæ•°æ®å­˜å‚¨.

#### 9.2.5 å¯åŠ¨

```shell
systemctl daemon-reload
systemctl start grafana-server
systemctl enable grafana-server
```

æµè§ˆå™¨æ‰“å¼€ï¼šhttp://node1:3000

é»˜è®¤è´¦æˆ·å¯†ç ï¼šadmin/admin