# Whisper-WebUI 完整使用流程

## 1 📋 项目概述

**Whisper-WebUI** 是基于OpenAI Whisper的Web界面版本，使用Gradio构建，支持视频转字幕功能。

项目地址：https://github.com/jhj0517/Whisper-WebUI

## 2 🛠️ 安装步骤

### 2.1 方法一：Docker部署（推荐）

```bash
# 1. 克隆项目
git clone https://github.com/jhj0517/Whisper-WebUI.git
cd Whisper-WebUI

# 2. 使用Docker构建
docker build -t whisper-webui .

# 3. 运行容器
docker run -d -p 7860:7860 --gpus all whisper-webui
```

### 2.2 方法二：本地安装

```bash
# 1. 克隆项目
git clone https://github.com/jhj0517/Whisper-WebUI.git
cd Whisper-WebUI

# 2. 创建虚拟环境
python -m venv venv
source venv/bin/activate  # Linux/Mac
# 或 venv\Scripts\activate  # Windows

# 3. 安装依赖
pip install -r requirements.txt

# 4. 运行应用
python app.py
```

## 3 🔧 配置Google Cloud Speech-to-Text API

### 3.1 获取API密钥

```bash
# 在Google Cloud Console中：
# 1. 创建项目
# 2. 启用Speech-to-Text API
# 3. 创建服务账户
# 4. 下载JSON密钥文件
```

### 3.2 配置环境变量

```bash
# 设置认证文件路径
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/credentials.json"
```

### 3.3 修改代码集成API

在项目中创建 `config.py`：

```python
import os
from google.cloud import speech

# Google Cloud Speech配置
def get_speech_client():
    return speech.SpeechClient()

# API配置
SPEECH_CONFIG = {
    "language_code": "zh-CN",  # 中文
    "sample_rate_hertz": 16000,
    "encoding": speech.RecognitionConfig.AudioEncoding.LINEAR16,
}
```

## 4 🚀 使用流程

### 4.1 启动服务

```bash
# 访问Web界面
http://localhost:7860
```

### 4.2 上传视频文件

- 支持格式：MP4, AVI, MOV, MKV等
- 文件大小：建议小于500MB
- 时长：建议小于2小时

### 4.3 配置参数

- **Model**: 选择Whisper模型（tiny, base, small, medium, large）
- **Language**: 选择语言（自动检测或指定）
- **Task**: 选择任务类型（transcribe或translate）

### 4.4 开始转换

- 点击"Submit"按钮
- 等待处理完成
- 下载生成的字幕文件

## 5 📁 输出文件格式

```
outputs/
├── video_name.srt          # 字幕文件
├── video_name.txt          # 纯文本
├── video_name.vtt          # WebVTT格式
└── video_name_audio.wav    # 提取的音频
```

## 6 ⚡ 性能优化

### 6.1 GPU加速

```bash
# 安装CUDA版本的PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 6.2 模型选择建议

- **tiny**: 速度最快，精度较低
- **base**: 平衡选择
- **small**: 推荐日常使用
- **medium**: 高精度要求
- **large**: 最高精度，速度较慢

## 7 🔄 集成Google Cloud Speech-to-Text

### 7.1 修改核心文件

编辑 `modules/whisper_inference.py`：

```python
def transcribe_with_google_cloud(audio_path, config):
    """使用Google Cloud Speech-to-Text API"""
    from google.cloud import speech
    
    client = speech.SpeechClient()
    
    with open(audio_path, "rb") as audio_file:
        content = audio_file.read()
    
    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="zh-CN",
        enable_automatic_punctuation=True,
        enable_word_time_offsets=True,
    )
    
    response = client.recognize(config=config, audio=audio)
    
    return response
```

## 8 🐛 常见问题

### 8.1 依赖安装失败

```bash
# 升级pip
pip install --upgrade pip
# 单独安装ffmpeg
conda install ffmpeg  # 或使用系统包管理器
```

### 8.2 GPU未被识别

```bash
# 检查CUDA安装
nvidia-smi
# 重新安装PyTorch GPU版本
```

### 8.3 内存不足

- 使用更小的Whisper模型
- 分段处理长视频
- 降低音频采样率

## 9 📊 使用建议

1. **首次使用**：选择"base"模型测试
2. **中文视频**：语言设置为"Chinese"
3. **长视频**：考虑分段处理
4. **高精度需求**：使用"large"模型 + Google Cloud API
5. **批量处理**：编写脚本调用API接口

现在你可以开始使用了！需要我帮你解决安装过程中的任何问题吗？